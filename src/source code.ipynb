{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP project src GROUP 15.ipynb","provenance":[],"collapsed_sections":["Ket_qTlncu18","xLClljKlLebC","W-60m3WMLbDw","4XsilH0KEUL8","xoVGA1-rnl-4","G2WTXL7X6gYi","3h4SddtjFALz","9TABqn8iIuVk","VpxpsuZAI993","TU9eAzeYelbn","LH0Nipo-Jtmz","XPsbfVYEKx2U","ff2wdwSxZFoD","cW5LpXrLacJn","BNDterVPezP2","2bZQkeFOhUIp","wJ5Zx3P8hVl2","mpAUc_gIhKjr","_Og3yGDfh4d4","X20pf5AKiUnt","yRGdIvD9iY4o","b1tgtFowj1HD","HfIvD4EhkXJK","TvvT6m6Rk3h2"],"authorship_tag":"ABX9TyNw1ZJpIKMAeqv2B71tPMIt"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UQEvaLzZnS5j","colab_type":"text"},"source":["#Paper: Model Explorations in Abstractive Summarisation"]},{"cell_type":"markdown","metadata":{"id":"LOq-iHYx4dwu","colab_type":"text"},"source":["GROUP 15:  \n","Youning Xia (19054254)\n","Yan Song (9898418)\n","Shuyi Han (19060915)\n","Wan Jing Song (17130843)\n"]},{"cell_type":"markdown","metadata":{"id":"-76k3FI_mn05","colab_type":"text"},"source":["This paper sets out to assess the performanceof Deep Reinforcement Learning (DRL) basedabstractive summarization models.  4 differentmodel variants are applied on 3 datasets andevaluate on ROUGE and BERTScores. Work-ing  on  the  novel  WikiHow  dataset  (Koupaeeand Wang, 2018) which is slightly more com-plex to train on has magnified the characteris-tics of the models.   It exposes the instabilityof  training  on  ROUGE-L  scores  and  suggestBERTScore as an alternative."]},{"cell_type":"markdown","metadata":{"id":"_0X4ZhGynav4","colab_type":"text"},"source":["#Source code"]},{"cell_type":"markdown","metadata":{"id":"w_TgiQtzrQAp","colab_type":"text"},"source":["\n","\n","1.   Data pre-processing\n","2.   Dataset files\n","3.   Package installed\n","4.   model configuration\n","5.   Vocabulary class\n","6.   Batcher\n","7.   Model with global attention mechanism\n","8.   Training utility\n","9.   Training class with ROUGE reward function\n","10.  Training class with BERTScore reward function\n","11.  Beam search class\n","12.  ROUGE Evaluation class(validating and testing)\n","13.  BERTScore Evaluation class \n","14.  Model with local attention machanism\n","15.  Experiment on three datasets.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ket_qTlncu18","colab_type":"text"},"source":["#1.Data pre-processing"]},{"cell_type":"code","metadata":{"id":"DSeCobMQdFAG","colab_type":"code","colab":{}},"source":["import os\n","import shutil\n","import collections\n","import tqdm\n","from tensorflow.core.example import example_pb2\n","import struct\n","import random\n","import shutil\n","\n","finished_path = \"/Users/youning/Documents/UCL_CSML/CSML_Lecture/COMP0087_NLP/Text-Summarizer-Pytorch-master/data/finished\"      \n","unfinished_path = \"/Users/youning/Documents/UCL_CSML/CSML_Lecture/COMP0087_NLP/Text-Summarizer-Pytorch-master/data/unfinished\"\n","chunk_path = \"/Users/youning/Documents/UCL_CSML/CSML_Lecture/COMP0087_NLP/Text-Summarizer-Pytorch-master/data/chunked\"\n","\n","vocab_path = \"/Users/youning/Documents/UCL_CSML/CSML_Lecture/COMP0087_NLP/Text-Summarizer-Pytorch-master/data/vocab\"\n","VOCAB_SIZE = 200000\n","\n","CHUNK_SIZE = 1500                           # num examples per chunk, for the chunked data\n","train_bin_path = os.path.join(finished_path, \"train.bin\")\n","valid_bin_path = os.path.join(finished_path, \"valid.bin\")\n","test_bin_path = os.path.join(finished_path, \"test.bin\")\n","\n","def make_folder(folder_path):\n","    if not os.path.exists(folder_path):\n","        os.makedirs(folder_path)\n","\n","def delete_folder(folder_path):\n","    if os.path.exists(folder_path):\n","        shutil.rmtree(folder_path)\n","\n","def shuffle_text_data(unshuffled_art, unshuffled_abs, shuffled_art, shuffled_abs):\n","    article_itr = open(os.path.join(unfinished_path, unshuffled_art), \"r\")\n","    abstract_itr = open(os.path.join(unfinished_path, unshuffled_abs), \"r\")\n","    list_of_pairs = []\n","    for article in article_itr:\n","        article = article.strip()\n","        abstract = next(abstract_itr).strip()\n","        list_of_pairs.append((article, abstract))\n","    article_itr.close()\n","    abstract_itr.close()\n","    random.shuffle(list_of_pairs)\n","    article_itr = open(os.path.join(unfinished_path, shuffled_art), \"w\")\n","    abstract_itr = open(os.path.join(unfinished_path, shuffled_abs), \"w\")\n","    for pair in list_of_pairs:\n","        article_itr.write(pair[0]+\"\\n\")\n","        abstract_itr.write(pair[1]+\"\\n\")\n","    article_itr.close()\n","    abstract_itr.close()\n","\n","def write_to_bin(article_path, abstract_path, out_file, vocab_counter = None):\n","\n","    with open(out_file, 'wb') as writer:\n","\n","        article_itr = open(article_path, 'r')\n","        abstract_itr = open(abstract_path, 'r')\n","        for article in tqdm.tqdm(article_itr):\n","            article = article.strip()\n","            abstract = next(abstract_itr).strip()\n","\n","            tf_example = example_pb2.Example()\n","            tf_example.features.feature['article'].bytes_list.value.extend([bytes(article, encoding= 'utf-8')])\n","            tf_example.features.feature['abstract'].bytes_list.value.extend([bytes(abstract, encoding= 'utf-8')])\n","            tf_example_str = tf_example.SerializeToString()\n","            str_len = len(tf_example_str)\n","            writer.write(struct.pack('q', str_len))\n","            writer.write(struct.pack('%ds' % str_len, tf_example_str))\n","\n","            if vocab_counter is not None:\n","                art_tokens = article.split(' ')\n","                abs_tokens = abstract.split(' ')\n","                # abs_tokens = [t for t in abs_tokens if\n","                #               t not in [SENTENCE_START, SENTENCE_END]]  # remove these tags from vocab\n","                tokens = art_tokens + abs_tokens\n","                tokens = [t.strip() for t in tokens]  # strip\n","                tokens = [t for t in tokens if t != \"\"]  # remove empty\n","                vocab_counter.update(tokens)\n","\n","    if vocab_counter is not None:\n","        with open(vocab_path, 'w') as writer:\n","            for word, count in vocab_counter.most_common(VOCAB_SIZE):\n","                writer.write(word + ' ' + str(count) + '\\n')\n","\n","\n","def creating_finished_data():\n","    make_folder(finished_path)\n","\n","    vocab_counter = collections.Counter()\n","\n","    write_to_bin(os.path.join(unfinished_path, \"train.art.shuf.txt\"), os.path.join(unfinished_path, \"train.abs.shuf.txt\"), train_bin_path, vocab_counter)\n","    write_to_bin(os.path.join(unfinished_path, \"valid.art.shuf.txt\"), os.path.join(unfinished_path, \"valid.abs.shuf.txt\"), valid_bin_path)\n","    write_to_bin(os.path.join(unfinished_path, \"test.art.shuf.txt\"), os.path.join(unfinished_path, \"test.abs.shuf.txt\"), test_bin_path)\n","\n","\n","def chunk_file(set_name, chunks_dir, bin_file):\n","    make_folder(chunks_dir)\n","    reader = open(bin_file, \"rb\")\n","    chunk = 0\n","    finished = False\n","    while not finished:\n","        chunk_fname = os.path.join(chunks_dir, '%s_%04d.bin' % (set_name, chunk)) # new chunk\n","        with open(chunk_fname, 'wb') as writer:\n","            for _ in range(CHUNK_SIZE):\n","                len_bytes = reader.read(8)\n","                if not len_bytes:\n","                    finished = True\n","                    break\n","                str_len = struct.unpack('q', len_bytes)[0]\n","                example_str = struct.unpack('%ds' % str_len, reader.read(str_len))[0]\n","                writer.write(struct.pack('q', str_len))\n","                writer.write(struct.pack('%ds' % str_len, example_str))\n","            chunk += 1\n","\n","\n","if __name__ == \"__main__\":\n","    shuffle_text_data(\"train.article.txt\", \"train.title.txt\", \"train.art.shuf.txt\", \"train.abs.shuf.txt\")\n","    shuffle_text_data(\"valid.article.filter.txt\", \"valid.title.filter.txt\", \"valid.art.shuf.txt\", \"valid.abs.shuf.txt\")\n","    shuffle_text_data(\"test.article.filter.txt\", \"test.title.filter.txt\", \"test.art.shuf.txt\", \"test.abs.shuf.txt\")\n","    print(\"Completed shuffling train & valid & test text files\")\n","    delete_folder(finished_path)\n","    creating_finished_data()        #create bin files\n","    print(\"Completed creating bin file for train & valid & test\")\n","    delete_folder(chunk_path)\n","    chunk_file(\"train\", os.path.join(chunk_path, \"train\"), train_bin_path)\n","    chunk_file(\"valid\", os.path.join(chunk_path, \"main_valid\"), valid_bin_path)\n","    chunk_file(\"test\", os.path.join(chunk_path, \"main_test\"), test_bin_path)\n","    print(\"Completed chunking main bin files into smaller ones\")\n","    #Performing rouge evaluation on 1.9 lakh sentences takes lot of time. So, create mini validation set & test set by borrowing 15k samples each from these 1.9 lakh sentences\n","    make_folder(os.path.join(chunk_path, \"valid\"))\n","    make_folder(os.path.join(chunk_path, \"test\"))\n","    bin_chunks = os.listdir(os.path.join(chunk_path, \"main_valid\"))\n","    bin_chunks.sort()\n","    samples = random.sample(set(bin_chunks[:-1]), 2)  # Exclude last bin file; contains only 9k sentences\n","    valid_chunk, test_chunk = samples[0], samples[1]\n","    shutil.copyfile(os.path.join(chunk_path, \"main_valid\", valid_chunk),os.path.join(chunk_path, \"valid\", \"valid_00.bin\"))\n","    shutil.copyfile(os.path.join(chunk_path, \"main_valid\", test_chunk), os.path.join(chunk_path, \"test\", \"test_00.bin\"))\n","\n","    # delete_folder(finished)\n","    # delete_folder(os.path.join(chunk_path, \"main_valid\"))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xLClljKlLebC","colab_type":"text"},"source":["#2.Dataset"]},{"cell_type":"code","metadata":{"id":"Y7e3Ia-aRVw4","colab_type":"code","colab":{}},"source":["from google.colab import drive                  #Most of these files are shared on google drive, you can simply save them into you personal drive and have access directly\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p6x8TAwMLhDu","colab_type":"text"},"source":["##A. Gigaword dataset(3.8M) \n","\n","\n","\n","1.   Binary data files: containing the chunked training, validation and testing data file in binary format. **LINK**:  https://drive.google.com/drive/folders/1se96ql8HQx1Sg1EiJ66NchqH2BWm3vEM?usp=sharing\n","\n","2.   pre-trained model: ML training for 10,000 iterations. **LINK**:  https://drive.google.com/file/d/1tEiDx77a9Tf6AA8vYHC6t2tIF966Uj2f/view?usp=sharing\n","\n","\n","\n","3.   **ML** all training checkpointed models for validating purpose:  10,000 - 20,000 itrations. **LINK**: https://drive.google.com/drive/folders/1HFqaVSc56CFwAk7S9AT9yv29bzlZNrVA?usp=sharing\n","\n","\n","\n","4.   **ML+RL(r)** all training checkpointed models for validating purpose:  10,000-20,000 iterations. **LINK**: https://drive.google.com/open?id=16u6iaVKmSg636V1VlVHIAxiy0b17svDb\n","\n","\n","\n","5.   **RL(r), RL(b)**: all training checkpointed models for validating purpose: these models files are currently not on google drive, available upon request.\n","\n","6.   **Testing models files**: contain testing models for ROUGE and BERTScore testing. **LINK**: https://drive.google.com/drive/folders/1HxaIm1VuCu7tQKBplQvA-WU1NpijGv0t?usp=sharing\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7F9Lsy-NVEax","colab_type":"text"},"source":["##B. CNN/DM dataset(287K)\n","\n","\n","\n","1.   Binary data files: chunked training, validation, testing binary data files. **LINK**: https://drive.google.com/drive/folders/1_-qeitl6QmFoa_At8bZXlvvfsEVxHoNV?usp=sharing ;  vocab file: https://drive.google.com/file/d/1INJZ7F5vwqISG5lgbn-3FXIz8hqDr390/view?usp=sharing\n","\n","2.   Pre-trained models(**ML**): 10,000 iterations. LINK: https://drive.google.com/file/d/1-aOEDsjrYNaQed_HfgFZmI19x1Wu-mCo/view?usp=sharing\n","\n","3.   **ML** training files: LINK: https://drive.google.com/drive/folders/155ldJSInimq06Xo7cdhkfCeSI8QNypem?usp=sharing\n","\n","4.   **ML+RL** training files:  LINK: https://drive.google.com/drive/folders/1WuESSVflSyt92G28yu0pfEzlksxRgOt3?usp=sharing\n","\n","\n","\n","5.   **RL(r)** training models files:  LINK: https://drive.google.com/drive/folders/1j1GKlRhX3VtkKEnKINtM3IpU3QkIFk_3?usp=sharing\n","\n","\n","6.  **RL(b)** training models files: LINK:  https://drive.google.com/drive/folders/1HeF2NOK8u9b9a1Q-bZS6lNvliPGlQApc?usp=sharing\n","\n","7.  **Testing models files**:  https://drive.google.com/drive/folders/1w8dqO4IMQVP6LCGosTb0cJ_3095VRTk4?usp=sharing\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"73uX_Z8iuVOn","colab_type":"text"},"source":["##C. WikiHow dataset (161K)\n","\n","1.   Binary data files:  https://drive.google.com/drive/folders/1oaYyf3NPYYbrnJCRXt6OAb4ngAX8UsTZ?usp=sharing\n","\n","2.   Pre-trained(**ML**) models:  LINK: https://drive.google.com/file/d/1-_AIyVz-4T0VOYE7PSSaUdrw_MG6lonT/view?usp=sharing\n","\n","3.   **ML** training model files:  https://drive.google.com/drive/folders/15w-hSaHmhGkTzFlABct6LnYjjgHZjs-0?usp=sharing\n","\n","\n","4.   **ML+RL(r)** tarining model files:  Available upon request.\n","\n","\n","5.   **RL(r)** training mdoel files:  LINK: https://drive.google.com/drive/folders/1gPPBGrYQkGd06kcCkJ-TdCtilFPPPkGv?usp=sharing\n","\n","\n","6.  **RL(b)** training models files:  available upon request.\n","\n","7.  **Testing models files**: https://drive.google.com/drive/folders/1pmJ7BfxENJTjp8RdjBK_S8DEYL3bnmih?usp=sharing\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"MxilmcMJLf3Z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W-60m3WMLbDw","colab_type":"text"},"source":["#3. Package"]},{"cell_type":"code","metadata":{"id":"rHgsXvknLDXO","colab_type":"code","colab":{}},"source":["pip install rouge           #ROUGE metric"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oBP394NNLF1k","colab_type":"code","colab":{}},"source":["pip install bert-score      #BERTScore"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IaDYq86aqqLq","colab_type":"code","colab":{}},"source":["import glob\n","import random\n","import struct\n","import csv\n","from tensorflow.core.example import example_pb2\n","import numpy as np\n","\n","import queue as Queue\n","import time\n","from random import shuffle\n","from threading import Thread\n","\n","\n","import tensorflow as tf\n","\n","import torch as T\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import torch.nn.functional as F\n","\n","import os\n","\n","from rouge import Rouge\n","import argparse\n","\n","\n","import shutil\n","import collections\n","import tqdm\n","\n","import gc\n","import bert_score\n","import argparse\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4XsilH0KEUL8","colab_type":"text"},"source":["#4. Config"]},{"cell_type":"code","metadata":{"id":"s1-FhSoVEVXH","colab_type":"code","colab":{}},"source":["train_data_path = \t'drive/My Drive/final WIKIHOW/WikiHow_bin/wiki_chunked/train/train_*'   #this is the location of trunked training files                         #\"drive/My Drive/WikiHow_bin/wiki_chunked/train/train_*\"\n","valid_data_path =  'drive/My Drive/final WIKIHOW/WikiHow_bin/wiki_chunked/main_valid/valid_0000.bin'\n","\n","vocab_path = \t\t'drive/My Drive/final WIKIHOW/WikiHow_bin/vocab_wiki'\n","   #this is the location of vocab                                                            #\"drive/My Drive/WikiHow_bin/vocab_wiki\"\n","\n","\n","# Hyperparameters\n","hidden_dim = 512\n","emb_dim = 256\n","batch_size =  10          #10\n","max_enc_steps = 800\n","max_dec_steps = 150\n","beam_size = 4\n","min_dec_steps= 3\n","vocab_size = 20000\n","\n","lr = 0.001\n","rand_unif_init_mag = 0.02\n","trunc_norm_init_std = 1e-4\n","max_batch_queue = 30        # max number of batches the batch_queue can hold\n","\n","eps = 1e-12\n","max_iterations = 15000\n","\n","\n","save_model_path = 'drive/My Drive/local pre'  #this is the location of pre-trained model                                          #'drive/My Drive/RL_wiki_model'             #\"drive/My Drive/wiki_model\"\n","new_save_model_path = 'drive/My Drive/local RLb'  #this is the location you want your new model to be saved    #'drive/My Drive/RL_wiki_model'\n","\n","intra_encoder = False\n","intra_decoder = True\n","local_attention_d = 100"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xoVGA1-rnl-4","colab_type":"text"},"source":["#5. Vocab"]},{"cell_type":"code","metadata":{"id":"6nZM6c9smm_R","colab_type":"code","colab":{}},"source":["\n","SENTENCE_START = '<s>'      # <s> and </s> are used in the data files to segment the abstracts into sentences. They don't receive vocab ids.\n","SENTENCE_END = '</s>'       # or <t>, </t>\n","\n","PAD_TOKEN = '[PAD]'         # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n","UNKNOWN_TOKEN = '[UNK]'     # This has a vocab id, which is used to represent out-of-vocabulary words\n","START_DECODING = '[START]'  # This has a vocab id, which is used at the start of every decoder input sequence\n","STOP_DECODING = '[STOP]'    # This has a vocab id, which is used at the end of untruncated target sequences\n","\n","# Note: none of <s>, </s>, [PAD], [UNK], [START], [STOP] should appear in the vocab file.\n","\n","class Vocab(object):\n","  \"\"\"Vocabulary class for mapping between words and ids (integers)\"\"\"\n","\n","  def __init__(self, vocab_file, max_size):\n","    \"\"\"Creates a vocab of up to max_size words, reading from the vocab_file. If max_size is 0, reads the entire vocab file.\n","\n","    param  vocab_file: path to the vocab file, which is assumed to contain \"<word> <frequency>\" on each line, sorted with most frequent word first. This code doesn't actually use the frequencies, though.\n","    param  max_size: integer. The maximum size of the resulting Vocabulary.\"\"\"\n","    self._word_to_id = {}                                                       #dictionary with word as key\n","    self._id_to_word = {}                                                       #           with id as key\n","    self._count = 0                                                             # keeps track of total number of words in the Vocab\n","\n","    # [UNK], [PAD], [START] and [STOP] get the ids 0,1,2,3.\n","    for w in [UNKNOWN_TOKEN, PAD_TOKEN, START_DECODING, STOP_DECODING]:\n","      self._word_to_id[w] = self._count                                         #fill in the dict\n","      self._id_to_word[self._count] = w     \n","      self._count += 1\n","\n","    # Read the vocab file and add words up to max_size\n","    with open(vocab_file, 'r') as vocab_f:\n","      for line in vocab_f:\n","        pieces = line.split()                                                   #list with two elements, the first is word the other one is its id\n","        if len(pieces) != 2:\n","          print('Warning: incorrectly formatted line in vocabulary file: %s\\n' % line)\n","          continue\n","        w = pieces[0]                                                           #word\n","        if w in [SENTENCE_START, SENTENCE_END, UNKNOWN_TOKEN, PAD_TOKEN, START_DECODING, STOP_DECODING]:        #raise error if these words exist in vocab\n","          raise Exception('<s>, </s>, [UNK], [PAD], [START] and [STOP] shouldn\\'t be in the vocab file, but %s is' % w)\n","        if w in self._word_to_id:                                             \n","          raise Exception('Duplicated word in vocabulary file: %s' % w)         #Duplication error\n","        self._word_to_id[w] = self._count                                       #assign id to word\n","        self._id_to_word[self._count] = w                                       #assign word to id\n","        self._count += 1                                                        #id increment\n","        if max_size != 0 and self._count >= max_size:                           #stop assigning when max_size has been reached\n","          print(\"max_size of vocab was specified as %i; we now have %i words. Stopping reading.\" % (max_size, self._count))\n","          break\n","\n","    print(\"Finished constructing vocabulary of %i total words. Last word added: %s\" % (self._count, self._id_to_word[self._count-1]))\n","\n","  def word2id(self, word):\n","    \"\"\"Returns the id (integer) of a word (string). Returns [UNK] id if word is OOV.\"\"\"\n","    if word not in self._word_to_id:\n","      return self._word_to_id[UNKNOWN_TOKEN]\n","    return self._word_to_id[word]\n","\n","  def id2word(self, word_id):\n","    \"\"\"Returns the word (string) corresponding to an id (integer).\"\"\"\n","    if word_id not in self._id_to_word:\n","      raise ValueError('Id not found in vocab: %d' % word_id)\n","    return self._id_to_word[word_id]\n","\n","  def size(self):\n","    \"\"\"Returns the total size of the vocabulary\"\"\"\n","    return self._count\n","  '''\n","  def write_metadata(self, fpath):\n","    \"\"\"Writes metadata file for Tensorboard word embedding visualizer as described here:\n","      https://www.tensorflow.org/get_started/embedding_viz\n","    Args:\n","      fpath: place to write the metadata file\n","    \"\"\"\n","    print(\"Writing word embedding metadata file to %s...\" % (fpath))\n","    with open(fpath, \"w\") as f:\n","      fieldnames = ['word']\n","      writer = csv.DictWriter(f, delimiter=\"\\t\", fieldnames=fieldnames)\n","      for i in range(self.size()):\n","        writer.writerow({\"word\": self._id_to_word[i]})\n","  '''\n","\n","\n","\n","\n","def example_generator(data_path, single_pass):\n","  \"\"\"Generates tf.Examples from data files.\n","    Binary data format: <length><blob>. <length> represents the byte size\n","    of <blob>. <blob> is serialized tf.Example proto. The tf.Example contains\n","    the tokenized article text and summary.\n","    https://www.tensorflow.org/tutorials/load_data/tfrecord\n","\n","    param  data_path:\n","      Path to tf.Example data files. Can include wildcards, e.g. if you have several training data chunk files train_001.bin, train_002.bin, etc, then pass data_path=train_* to access them all.\n","    param  single_pass:\n","      Boolean. If True, go through the dataset exactly once, generating examples in the order they appear, then return. Otherwise, generate random examples indefinitely.\n","    Yields:\n","      Deserialized tf.Example.\n","  \"\"\"\n","  while True:\n","    filelist = glob.glob(data_path)                                             # get the list of datafiles\n","    assert filelist, ('Error: Empty filelist at %s' % data_path)                # check filelist isn't empty\n","    if single_pass:\n","      filelist = sorted(filelist)\n","    else:\n","      random.shuffle(filelist)                                                  #random shuffle the data if not single_pass\n","    for f in filelist:\n","      reader = open(f, 'rb')\n","      while True:\n","        len_bytes = reader.read(8)\n","        if not len_bytes: break # finished reading this file\n","        str_len = struct.unpack('q', len_bytes)[0]\n","        example_str = struct.unpack('%ds' % str_len, reader.read(str_len))[0]\n","        yield example_pb2.Example.FromString(example_str)\n","    if single_pass:\n","      print(\"example_generator completed reading all datafiles. No more data.\")\n","      break\n","\n","\n","def article2ids(article_words, vocab):\n","  \"\"\"Map the article words to their ids. Also return a list of OOVs in the article.\n","  Args:\n","    article_words: list of words (strings)\n","    vocab: Vocabulary object\n","  Returns:\n","    ids:\n","      A list of word ids (integers); OOVs are represented by their temporary article OOV number. If the vocabulary size is 50k and the article has 3 OOVs, then these temporary OOV numbers will be 50000, 50001, 50002.\n","    oovs:\n","      A list of the OOV words in the article (strings), in the order corresponding to their temporary article OOV numbers.\"\"\"\n","  ids = []\n","  oovs = []\n","  unk_id = vocab.word2id(UNKNOWN_TOKEN)\n","  for w in article_words:\n","    i = vocab.word2id(w)\n","    if i == unk_id:                         # If w is OOV\n","      if w not in oovs:                     # Add to list of OOVs\n","        oovs.append(w)\n","      oov_num = oovs.index(w)               # This is 0 for the first article OOV, 1 for the second article OOV...\n","      ids.append(vocab.size() + oov_num)    # This is e.g. 50000 for the first article OOV, 50001 for the second...(append at the end)\n","    else:\n","      ids.append(i)\n","  return ids, oovs\n","\n","\n","def abstract2ids(abstract_words, vocab, article_oovs):\n","  \"\"\"Map the abstract words to their ids. In-article OOVs are mapped to their temporary OOV numbers.\n","  Args:\n","    abstract_words: list of words (strings)\n","    vocab: Vocabulary object\n","    article_oovs: list of in-article OOV words (strings), in the order corresponding to their temporary article OOV numbers\n","  Returns:\n","    ids: List of ids (integers). In-article OOV words are mapped to their temporary OOV numbers. Out-of-article OOV words are mapped to the UNK token id.\"\"\"\n","  ids = []\n","  unk_id = vocab.word2id(UNKNOWN_TOKEN)\n","  for w in abstract_words:\n","    i = vocab.word2id(w)\n","    if i == unk_id:                         # If w is an OOV word\n","      if w in article_oovs:                 # If w is an in-article OOV\n","        vocab_idx = vocab.size() + article_oovs.index(w)    # Map to its temporary article OOV number\n","        ids.append(vocab_idx)\n","      else:                                 # If w is an out-of-article OOV\n","        ids.append(unk_id)                  # Map to the UNK token id\n","    else:\n","      ids.append(i)\n","  return ids\n","\n","\n","def outputids2words(id_list, vocab, article_oovs):\n","  \"\"\"Maps output ids to words, including mapping in-article OOVs from their temporary ids to the original OOV string (applicable in pointer-generator mode).\n","\n","    param  id_list: list of ids (integers)\n","            vocab: Vocabulary object\n","    param  article_oovs: list of OOV words (strings) in the order corresponding to their temporary article OOV ids (that have been assigned in pointer-generator mode), or None (in baseline mode)\n","    Returns:\n","            words: list of words (strings)\n","  \"\"\"\n","  words = []\n","  for i in id_list:\n","    try:\n","      w = vocab.id2word(i) # might be [UNK]\n","    except ValueError as e: # w is OOV\n","      assert article_oovs is not None, \"Error: model produced a word ID that isn't in the vocabulary. This should not happen in baseline (no pointer-generator) mode\"\n","      article_oov_idx = i - vocab.size()\n","      try:\n","        w = article_oovs[article_oov_idx]\n","      except ValueError as e: # i doesn't correspond to an article oov\n","        raise ValueError('Error: model produced word ID %i which corresponds to article OOV %i but this example only has %i article OOVs' % (i, article_oov_idx, len(article_oovs)))\n","    words.append(w) \n","  return words\n","\n","\n","def abstract2sents(abstract):\n","  \"\"\"Splits abstract text from datafile into list of sentences.\n","  Args:\n","    abstract: string containing <s> and </s> tags for starts and ends of sentences\n","  Returns:\n","    sents: List of sentence strings (no tags)\"\"\"\n","  cur = 0\n","  sents = []\n","  while True:\n","    try:\n","      start_p = abstract.index(SENTENCE_START, cur)\n","      end_p = abstract.index(SENTENCE_END, start_p + 1)\n","      cur = end_p + len(SENTENCE_END)\n","      sents.append(abstract[start_p+len(SENTENCE_START):end_p])\n","    except ValueError as e: # no more sentences\n","      return sents\n","\n","'''\n","def show_art_oovs(article, vocab):\n","  \"\"\"Returns the article string, highlighting the OOVs by placing __underscores__ around them\"\"\"\n","  unk_token = vocab.word2id(UNKNOWN_TOKEN)\n","  words = article.split(' ')\n","  words = [(\"__%s__\" % w) if vocab.word2id(w)==unk_token else w for w in words]\n","  out_str = ' '.join(words)\n","  return out_str\n","\n","\n","def show_abs_oovs(abstract, vocab, article_oovs):\n","  \"\"\"Returns the abstract string, highlighting the article OOVs with __underscores__.\n","  If a list of article_oovs is provided, non-article OOVs are differentiated like !!__this__!!.\n","  Args:\n","    abstract: string\n","    vocab: Vocabulary object\n","    article_oovs: list of words (strings), or None (in baseline mode)\n","  \"\"\"\n","  unk_token = vocab.word2id(UNKNOWN_TOKEN)\n","  words = abstract.split(' ')\n","  new_words = []\n","  for w in words:\n","    if vocab.word2id(w) == unk_token: # w is oov\n","      if article_oovs is None: # baseline mode\n","        new_words.append(\"__%s__\" % w)\n","      else: # pointer-generator mode\n","        if w in article_oovs:\n","          new_words.append(\"__%s__\" % w)\n","        else:\n","          new_words.append(\"!!__%s__!!\" % w)\n","    else: # w is in-vocab word\n","      new_words.append(w)\n","  out_str = ' '.join(new_words)\n","  return out_str\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G2WTXL7X6gYi","colab_type":"text"},"source":["#6. Batcher"]},{"cell_type":"code","metadata":{"id":"Znpb7BYNndnF","colab_type":"code","colab":{}},"source":["\n","import queue as Queue\n","import time\n","from random import shuffle\n","from threading import Thread\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","\n","import random\n","random.seed(1234)\n","\n","class Example(object):\n","    '''\n","    read article, abstrction and vocab and process them into batching-ready format\n","    '''\n","\n","  def __init__(self, article, abstract_sentences, vocab):\n","    # Get ids of special tokens\n","    start_decoding = vocab.word2id(START_DECODING)      #data\n","    stop_decoding = vocab.word2id(STOP_DECODING)        #data\n","\n","    # Process the article\n","    article_words = article.split()\n","    if len(article_words) > max_enc_steps:              #truncate the input article to max_enc_step length\n","      article_words = article_words[ : max_enc_steps]   \n","    self.enc_len = len(article_words)                   # store the length after truncation but before padding\n","    self.enc_input = [vocab.word2id(w) for w in article_words] # list of word ids; OOVs are represented by the id for UNK token\n","\n","    # Process the abstract\n","    abstract = ' '.join(abstract_sentences)                 # string\n","    abstract_words = abstract.split()                       # list of strings, split by space\n","    abs_ids = [vocab.word2id(w) for w in abstract_words]    # list of word ids; OOVs are represented by the id for UNK token\n","\n","    # Get the decoder input sequence and target sequence\n","    self.dec_input, _ = self.get_dec_inp_targ_seqs(abs_ids, max_dec_steps, start_decoding, stop_decoding)\n","    self.dec_len = len(self.dec_input)\n","\n","    # If using pointer-generator mode, we need to store some extra info\n","    # Store a version of the enc_input where in-article OOVs are represented by their temporary OOV id; also store the in-article OOVs words themselves\n","    self.enc_input_extend_vocab, self.article_oovs = article2ids(article_words, vocab)     #data\n","\n","    # Get a verison of the reference summary where in-article OOVs are represented by their temporary article OOV id\n","    abs_ids_extend_vocab = abstract2ids(abstract_words, vocab, self.article_oovs)           #data\n","\n","    # Get decoder target sequence\n","    _, self.target = self.get_dec_inp_targ_seqs(abs_ids_extend_vocab, max_dec_steps, start_decoding, stop_decoding)\n","\n","    # Store the original strings\n","    self.original_article = article\n","    self.original_abstract = abstract\n","    self.original_abstract_sents = abstract_sentences\n","\n","\n","\n","  def get_dec_inp_targ_seqs(self, sequence, max_len, start_id, stop_id):\n","    inp = [start_id] + sequence[:]\n","    target = sequence[:]\n","    if len(inp) > max_len: # truncate\n","      inp = inp[:max_len]\n","      target = target[:max_len] # no end_token\n","    else: # no truncation\n","      target.append(stop_id) # end token\n","    assert len(inp) == len(target)\n","    return inp, target\n","\n","\n","  def pad_decoder_inp_targ(self, max_len, pad_id):              #padding\n","    while len(self.dec_input) < max_len:\n","      self.dec_input.append(pad_id)\n","    while len(self.target) < max_len:\n","      self.target.append(pad_id)\n","\n","\n","  def pad_encoder_input(self, max_len, pad_id):                 #padding\n","    while len(self.enc_input) < max_len:\n","      self.enc_input.append(pad_id)\n","    while len(self.enc_input_extend_vocab) < max_len:\n","      self.enc_input_extend_vocab.append(pad_id)\n","\n","\n","\n","#-------------------------------------------------------------------------------------------------\n","\n","\n","class Batch(object):\n","  def __init__(self, example_list, vocab, batch_size):\n","    self.batch_size = batch_size\n","    self.pad_id = vocab.word2id(PAD_TOKEN)      # id of the PAD token used to pad sequences\n","    self.init_encoder_seq(example_list)         # initialize the input to the encoder\n","    self.init_decoder_seq(example_list)         # initialize the input and targets for the decoder\n","    self.store_orig_strings(example_list)       # store the original strings\n","\n","\n","  def init_encoder_seq(self, example_list):\n","    # Determine the maximum length of the encoder input sequence in this batch\n","    max_enc_seq_len = max([ex.enc_len for ex in example_list])\n","\n","    # Pad the encoder input sequences up to the length of the longest sequence\n","    for ex in example_list:\n","      ex.pad_encoder_input(max_enc_seq_len, self.pad_id)\n","\n","    # Initialize the numpy arrays\n","    # Note: our enc_batch can have different length (second dimension) for each batch because we use dynamic_rnn for the encoder.\n","    self.enc_batch = np.zeros((self.batch_size, max_enc_seq_len), dtype=np.int32)\n","    self.enc_lens = np.zeros((self.batch_size), dtype=np.int32)\n","    self.enc_padding_mask = np.zeros((self.batch_size, max_enc_seq_len), dtype=np.float32)\n","\n","    # Fill in the numpy arrays\n","    for i, ex in enumerate(example_list):\n","      self.enc_batch[i, :] = ex.enc_input[:]\n","      self.enc_lens[i] = ex.enc_len\n","      for j in range(ex.enc_len):\n","        self.enc_padding_mask[i][j] = 1\n","\n","    # For pointer-generator mode, need to store some extra info\n","    # Determine the max number of in-article OOVs in this batch\n","    self.max_art_oovs = max([len(ex.article_oovs) for ex in example_list])\n","    # Store the in-article OOVs themselves\n","    self.art_oovs = [ex.article_oovs for ex in example_list]\n","    # Store the version of the enc_batch that uses the article OOV ids\n","    self.enc_batch_extend_vocab = np.zeros((self.batch_size, max_enc_seq_len), dtype=np.int32)\n","    for i, ex in enumerate(example_list):\n","      self.enc_batch_extend_vocab[i, :] = ex.enc_input_extend_vocab[:]\n","\n","  def init_decoder_seq(self, example_list):\n","    # Pad the inputs and targets\n","    for ex in example_list:\n","      ex.pad_decoder_inp_targ(max_dec_steps, self.pad_id)           #config\n","\n","    # Initialize the numpy arrays.\n","    self.dec_batch = np.zeros((self.batch_size, max_dec_steps), dtype=np.int32)         #config\n","    self.target_batch = np.zeros((self.batch_size, max_dec_steps), dtype=np.int32)      #config\n","    # self.dec_padding_mask = np.zeros((self.batch_size, config.max_dec_steps), dtype=np.float32)\n","    self.dec_lens = np.zeros((self.batch_size), dtype=np.int32)\n","\n","    # Fill in the numpy arrays\n","    for i, ex in enumerate(example_list):\n","      self.dec_batch[i, :] = ex.dec_input[:]\n","      self.target_batch[i, :] = ex.target[:]\n","      self.dec_lens[i] = ex.dec_len\n","      # for j in range(ex.dec_len):\n","      #   self.dec_padding_mask[i][j] = 1\n","\n","  def store_orig_strings(self, example_list):\n","    self.original_articles = [ex.original_article for ex in example_list] # list of lists\n","    self.original_abstracts = [ex.original_abstract for ex in example_list] # list of lists\n","    self.original_abstracts_sents = [ex.original_abstract_sents for ex in example_list] # list of list of lists\n","\n","\n","#-------------------------------------------------------------------------------------------------\n","class Batcher(object):\n","  BATCH_QUEUE_MAX = max_batch_queue  #30 # max number of batches the batch_queue can hold\n","\n","  def __init__(self, data_path, vocab, mode, batch_size, single_pass):\n","    self._data_path = data_path\n","    self._vocab = vocab\n","    self._single_pass = single_pass\n","    self.mode = mode\n","    self.batch_size = batch_size\n","    # Initialize a queue of Batches waiting to be used, and a queue of Examples waiting to be batched\n","    self._batch_queue = Queue.Queue(self.BATCH_QUEUE_MAX)\n","    self._example_queue = Queue.Queue(self.BATCH_QUEUE_MAX * self.batch_size)\n","\n","    # Different settings depending on whether we're in single_pass mode or not\n","    if single_pass:\n","      self._num_example_q_threads = 1 # just one thread, so we read through the dataset just once\n","      self._num_batch_q_threads = 1  # just one thread to batch examples\n","      self._bucketing_cache_size = 1 # only load one batch's worth of examples before bucketing; this essentially means no bucketing\n","      self._finished_reading = False # this will tell us when we're finished reading the dataset\n","    else:\n","      self._num_example_q_threads = 1 #16 # num threads to fill example queue\n","      self._num_batch_q_threads = 1 #4  # num threads to fill batch queue\n","      self._bucketing_cache_size = 1 #100 # how many batches-worth of examples to load into cache before bucketing\n","\n","    # Start the threads that load the queues\n","    self._example_q_threads = []\n","    for _ in range(self._num_example_q_threads):\n","      self._example_q_threads.append(Thread(target=self.fill_example_queue))\n","      self._example_q_threads[-1].daemon = True\n","      self._example_q_threads[-1].start()\n","    self._batch_q_threads = []\n","    for _ in range(self._num_batch_q_threads):\n","      self._batch_q_threads.append(Thread(target=self.fill_batch_queue))\n","      self._batch_q_threads[-1].daemon = True\n","      self._batch_q_threads[-1].start()\n","\n","    # Start a thread that watches the other threads and restarts them if they're dead\n","    if not single_pass: # We don't want a watcher in single_pass mode because the threads shouldn't run forever\n","      self._watch_thread = Thread(target=self.watch_threads)\n","      self._watch_thread.daemon = True\n","      self._watch_thread.start()\n","\n","  def next_batch(self):\n","    # If the batch queue is empty, print a warning\n","    if self._batch_queue.qsize() == 0:\n","      # tf.logging.warning('Bucket input queue is empty when calling next_batch. Bucket queue size: %i, Input queue size: %i', self._batch_queue.qsize(), self._example_queue.qsize())\n","      if self._single_pass and self._finished_reading:\n","        tf.logging.info(\"Finished reading dataset in single_pass mode.\")\n","        return None\n","\n","    batch = self._batch_queue.get() # get the next Batch\n","    return batch\n","\n","  def fill_example_queue(self):\n","    input_gen = self.text_generator(example_generator(self._data_path, self._single_pass))\n","\n","    while True:\n","      try:\n","        (article, abstract) = next(input_gen) # read the next example from file. article and abstract are both strings.\n","      except StopIteration: # if there are no more examples:\n","        tf.logging.info(\"The example generator for this example queue filling thread has exhausted data.\")\n","        if self._single_pass:\n","          tf.logging.info(\"single_pass mode is on, so we've finished reading dataset. This thread is stopping.\")\n","          self._finished_reading = True\n","          break\n","        else:\n","          raise Exception(\"single_pass mode is off but the example generator is out of data; error.\")\n","\n","      # abstract_sentences = [sent.strip() for sent in data.abstract2sents(abstract)] # Use the <s> and </s> tags in abstract to get a list of sentences.\n","      abstract_sentences = [abstract.strip()]\n","      example = Example(article, abstract_sentences, self._vocab) # Process into an Example.\n","      self._example_queue.put(example) # place the Example in the example queue.\n","\n","  def fill_batch_queue(self):\n","    while True:\n","      if self.mode == 'decode':\n","        # beam search decode mode single example repeated in the batch\n","        ex = self._example_queue.get()\n","        b = [ex for _ in range(self.batch_size)]\n","        self._batch_queue.put(Batch(b, self._vocab, self.batch_size))\n","      else:\n","        # Get bucketing_cache_size-many batches of Examples into a list, then sort\n","        inputs = []\n","        for _ in range(self.batch_size * self._bucketing_cache_size):\n","          inputs.append(self._example_queue.get())\n","        inputs = sorted(inputs, key=lambda inp: inp.enc_len, reverse=True) # sort by length of encoder sequence\n","\n","        # Group the sorted Examples into batches, optionally shuffle the batches, and place in the batch queue.\n","        batches = []\n","        for i in range(0, len(inputs), self.batch_size):\n","          batches.append(inputs[i:i + self.batch_size])\n","        if not self._single_pass:\n","          shuffle(batches)\n","        for b in batches:  # each b is a list of Example objects\n","          self._batch_queue.put(Batch(b, self._vocab, self.batch_size))\n","\n","  def watch_threads(self):\n","    while True:\n","      tf.logging.info(\n","        'Bucket queue size: %i, Input queue size: %i',\n","        self._batch_queue.qsize(), self._example_queue.qsize())\n","\n","      time.sleep(60)\n","      for idx,t in enumerate(self._example_q_threads):\n","        if not t.is_alive(): # if the thread is dead\n","          tf.logging.error('Found example queue thread dead. Restarting.')\n","          new_t = Thread(target=self.fill_example_queue)\n","          self._example_q_threads[idx] = new_t\n","          new_t.daemon = True\n","          new_t.start()\n","      for idx,t in enumerate(self._batch_q_threads):\n","        if not t.is_alive(): # if the thread is dead\n","          tf.logging.error('Found batch queue thread dead. Restarting.')\n","          new_t = Thread(target=self.fill_batch_queue)\n","          self._batch_q_threads[idx] = new_t\n","          new_t.daemon = True\n","          new_t.start()\n","\n","\n","  def text_generator(self, example_generator):\n","    while True:\n","      e = next(example_generator) # e is a tf.Example\n","      try:\n","        article_text = e.features.feature['article'].bytes_list.value[0] # the article text was saved under the key 'article' in the data files\n","        abstract_text = e.features.feature['abstract'].bytes_list.value[0] # the abstract text was saved under the key 'abstract' in the data files\n","        article_text = article_text.decode()\n","        abstract_text = abstract_text.decode()\n","      except ValueError:\n","        tf.logging.error('Failed to get article or abstract from example')\n","        continue\n","      if len(article_text)==0: # See https://github.com/abisee/pointer-generator/issues/1\n","        #tf.logging.warning('Found an example with empty article text. Skipping it.')\n","        continue\n","      else:\n","        yield (article_text, abstract_text)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3h4SddtjFALz","colab_type":"text"},"source":["#7. Model with global attention "]},{"cell_type":"code","metadata":{"id":"x0ojgvpwndpq","colab_type":"code","colab":{}},"source":["'''\n","import torch as T\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import torch.nn.functional as F\n","'''\n","\n","def init_lstm_wt(lstm):                                 #initialisation \n","    for name, _ in lstm.named_parameters():\n","        if 'weight' in name:\n","            wt = getattr(lstm, name)\n","            #print(wt)\n","            wt.data = wt.data.uniform_(-rand_unif_init_mag, rand_unif_init_mag)\n","            #wt.uniform_(-rand_unif_init_mag, rand_unif_init_mag)     #commit\n","        elif 'bias' in name:\n","            # set forget bias to 1\n","            bias = getattr(lstm, name)\n","            n = bias.size(0)\n","            start, end = n // 4, n // 2\n","\n","            bias.data = bias.data.fill_(0.)\n","            #bias.fill_(0.)\n","            bias.data[start:end].fill_(1.)\n","\n","def init_linear_wt(linear):                             #initialisation\n","\n","    linear.weight.data = linear.weight.data.normal_(std=trunc_norm_init_std)\n","    #linear.weight.normal_(std=trunc_norm_init_std)\n","    if linear.bias is not None:\n","        linear.bias.data = linear.bias.data.normal_(std=trunc_norm_init_std)\n","        #linear.bias.normal_(std=trunc_norm_init_std)\n","\n","def init_wt_normal(wt):                                 #initialisation\n","    wt.data = wt.data.normal_(std=trunc_norm_init_std)\n","    #wt.normal_(std=trunc_norm_init_std)\n","\n","\n","class Encoder(nn.Module):\n","    \"\"\"\n","    bi-directional LSTM, reduced linear layer\n","    \"\"\"\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","\n","        self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)    #batch_true: If True, then the input and output tensors are provided as (batch, seq, feature)\n","        init_lstm_wt(self.lstm)\n","\n","        self.reduce_h = nn.Linear(hidden_dim * 2, hidden_dim)        #hidden state \n","        init_linear_wt(self.reduce_h)\n","        self.reduce_c = nn.Linear(hidden_dim * 2, hidden_dim)\n","        init_linear_wt(self.reduce_c)\n","\n","    def forward(self, x, seq_lens):\n","        \"\"\"\n","        param  x:  input sequence\n","        param  seq_len:  length of sequence\n","\n","        return:\n","        enc_out:  Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n","        (h_reduced, c_reduced):  Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n","        \"\"\"\n","        packed = pack_padded_sequence(x, seq_lens, batch_first=True)    #accepts any input that has at least two dimensions. You can apply it to pack the labels, and use the output of the RNN with them to compute the loss directly\n","        enc_out, enc_hid = self.lstm(packed)                            # tensor containing the hidden state for t = seq_len. and tensor containing the cell state for t = seq_len.\n","        enc_out,_ = pad_packed_sequence(enc_out, batch_first=True)      \n","        enc_out = enc_out.contiguous()                              #bs, n_seq, 2*n_hid\n","        h, c = enc_hid                                              #shape of h: 2, bs, n_hid\n","        h = T.cat(list(h), dim=1)                                   #bs, 2*n_hid\n","        c = T.cat(list(c), dim=1)\n","        h_reduced = F.relu(self.reduce_h(h))                        #bs,n_hid\n","        c_reduced = F.relu(self.reduce_c(c))\n","        return enc_out, (h_reduced, c_reduced)      #enc_out: all encoder\n","\n","\n","class encoder_attention(nn.Module):\n","\n","    def __init__(self):\n","        super(encoder_attention, self).__init__()\n","        self.W_h = nn.Linear(hidden_dim * 2, hidden_dim * 2, bias=False)    #no bias just the weight matrix\n","        self.W_s = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n","        self.v = nn.Linear(hidden_dim * 2, 1, bias=False)\n","\n","\n","    def forward(self, st_hat, h, enc_padding_mask, sum_temporal_srcs):              #INTRA-TEMPORAL ATTENTION ON INPUT SEQUENCE in paper?\n","        ''' Perform attention over encoder hidden states\n","        :param st_hat: decoder hidden state at current time step\n","        :param h: encoder hidden states\n","        :param enc_padding_mask:\n","        :param sum_temporal_srcs: if using intra-temporal attention, contains summation of attention weights from previous decoder time steps\n","        return\n","        ct_e: encoder context vector\n","        at:   attention weight\n","        sum_temporal_srcs:  sum of attention weights from previous decoder time steps, will need to be input again for next iteration\n","        '''\n","\n","        # Standard attention technique (eq 1 in https://arxiv.org/pdf/1704.04368.pdf)\n","        et = self.W_h(h)                        # bs,n_seq,2*n_hid\n","        dec_fea = self.W_s(st_hat).unsqueeze(1) # bs,1,2*n_hid\n","        et = et + dec_fea\n","        et = T.tanh(et)                         # bs,n_seq,2*n_hid\n","        et = self.v(et).squeeze(2)              # bs,n_seq\n","\n","        # intra-temporal attention     (eq 3 in https://arxiv.org/pdf/1705.04304.pdf)\n","        if intra_encoder:\n","            exp_et = T.exp(et)\n","            if sum_temporal_srcs is None:\n","                et1 = exp_et\n","                sum_temporal_srcs  = get_cuda(T.FloatTensor(et.size()).fill_(1e-10)) + exp_et           #defined temporal score\n","            else:\n","                et1 = exp_et/sum_temporal_srcs  #bs, n_seq\n","                sum_temporal_srcs = sum_temporal_srcs + exp_et\n","        else:\n","            et1 = F.softmax(et, dim=1)\n","\n","        # assign 0 probability for padded elements\n","        at = et1 * enc_padding_mask\n","        normalization_factor = at.sum(1, keepdim=True)\n","        at = at / normalization_factor\n","\n","        at = at.unsqueeze(1)                    #bs,1,n_seq\n","        # Compute encoder context vector\n","        ct_e = T.bmm(at, h)                     #bs, 1, 2*n_hid, batch matrix-matrix product of matrices (temporal score and encoder hidden state)\n","        ct_e = ct_e.squeeze(1)\n","        at = at.squeeze(1)\n","\n","        return ct_e, at, sum_temporal_srcs\n","\n","class decoder_attention(nn.Module):\n","    def __init__(self):\n","        super(decoder_attention, self).__init__()\n","        if intra_decoder:\n","            self.W_prev = nn.Linear(hidden_dim, hidden_dim, bias=False)        #weight\n","            self.W_s = nn.Linear(hidden_dim, hidden_dim)\n","            self.v = nn.Linear(hidden_dim, 1, bias=False)\n","\n","    def forward(self, s_t, prev_s):\n","        '''Perform intra_decoder attention\n","        Args\n","        :param s_t: hidden state of decoder at current time step\n","        :param prev_s: If intra_decoder attention, contains list of previous decoder hidden states\n","        '''\n","        if intra_decoder is False:\n","            ct_d = get_cuda(T.zeros(s_t.size()))\n","        elif prev_s is None:\n","            ct_d = get_cuda(T.zeros(s_t.size()))\n","            prev_s = s_t.unsqueeze(1)               #bs, 1, n_hid\n","        else:\n","            # Standard attention technique (eq 1 in https://arxiv.org/pdf/1704.04368.pdf)      e = v tanh(Wh + Ws + b)\n","            et = self.W_prev(prev_s)                # bs,t-1,n_hid\n","            dec_fea = self.W_s(s_t).unsqueeze(1)    # bs,1,n_hid\n","            et = et + dec_fea\n","            et = T.tanh(et)                         # bs,t-1,n_hid\n","            et = self.v(et).squeeze(2)              # bs,t-1\n","            # intra-decoder attention     (eq 7 & 8 in https://arxiv.org/pdf/1705.04304.pdf)\n","            at = F.softmax(et, dim=1).unsqueeze(1)  #bs, 1, t-1,  alpha\n","            ct_d = T.bmm(at, prev_s).squeeze(1)     #bs, n_hid\n","            prev_s = T.cat([prev_s, s_t.unsqueeze(1)], dim=1)    #bs, t, n_hid, keep adding previous hidden state \n","\n","        return ct_d, prev_s                 #decoder context vector, previous decoder hidden states\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","        self.enc_attention = encoder_attention()\n","        self.dec_attention = decoder_attention()\n","        self.x_context = nn.Linear(hidden_dim*2 + emb_dim, emb_dim)\n","\n","        self.lstm = nn.LSTMCell(emb_dim, hidden_dim)\n","        init_lstm_wt(self.lstm)\n","\n","        self.p_gen_linear = nn.Linear(hidden_dim * 5 + emb_dim, 1)\n","\n","        #p_vocab\n","        self.V = nn.Linear(hidden_dim*4, hidden_dim)\n","        self.V1 = nn.Linear(hidden_dim, vocab_size)\n","        init_linear_wt(self.V1)\n","\n","    def forward(self, x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s):\n","        x = self.x_context(T.cat([x_t, ct_e], dim=1))\n","        s_t = self.lstm(x, s_t)\n","\n","        dec_h, dec_c = s_t\n","        st_hat = T.cat([dec_h, dec_c], dim=1)\n","        ct_e, attn_dist, sum_temporal_srcs = self.enc_attention(st_hat, enc_out, enc_padding_mask, sum_temporal_srcs)\n","\n","        ct_d, prev_s = self.dec_attention(dec_h, prev_s)        #intra-decoder attention\n","\n","        p_gen = T.cat([ct_e, ct_d, st_hat, x], 1)\n","        p_gen = self.p_gen_linear(p_gen)            # bs,1\n","        p_gen = T.sigmoid(p_gen)                    # bs,1\n","\n","        out = T.cat([dec_h, ct_e, ct_d], dim=1)     # bs, 4*n_hid\n","        out = self.V(out)                           # bs,n_hid\n","        out = self.V1(out)                          # bs, n_vocab\n","        vocab_dist = F.softmax(out, dim=1)\n","        vocab_dist = p_gen * vocab_dist\n","        attn_dist_ = (1 - p_gen) * attn_dist\n","\n","        # pointer mechanism (as suggested in eq 9 https://arxiv.org/pdf/1704.04368.pdf)\n","        if extra_zeros is not None:\n","            vocab_dist = T.cat([vocab_dist, extra_zeros], dim=1)\n","        final_dist = vocab_dist.scatter_add(1, enc_batch_extend_vocab, attn_dist_)\n","\n","        return final_dist, s_t, ct_e, sum_temporal_srcs, prev_s\n","\n","\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder()\n","        self.embeds = nn.Embedding(vocab_size, emb_dim)\n","        init_wt_normal(self.embeds.weight)\n","\n","        self.encoder = get_cuda(self.encoder)\n","        self.decoder = get_cuda(self.decoder)\n","        self.embeds = get_cuda(self.embeds)\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9TABqn8iIuVk","colab_type":"text"},"source":["#8.train Util"]},{"cell_type":"code","metadata":{"id":"HzZYSLexndsI","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch as T\n","\n","\n","def get_cuda(tensor):\n","    if T.cuda.is_available():\n","        tensor = tensor.cuda()\n","    return tensor\n","\n","def get_enc_data(batch):\n","    batch_size = len(batch.enc_lens)\n","    enc_batch = T.from_numpy(batch.enc_batch).long()\n","    enc_padding_mask = T.from_numpy(batch.enc_padding_mask).float()\n","\n","    enc_lens = batch.enc_lens\n","\n","    ct_e = T.zeros(batch_size, 2*   hidden_dim)   #config.hidden_dim\n","\n","    enc_batch = get_cuda(enc_batch)\n","    enc_padding_mask = get_cuda(enc_padding_mask)\n","\n","    ct_e = get_cuda(ct_e)\n","\n","    enc_batch_extend_vocab = None\n","    if batch.enc_batch_extend_vocab is not None:\n","        enc_batch_extend_vocab = T.from_numpy(batch.enc_batch_extend_vocab).long()\n","        enc_batch_extend_vocab = get_cuda(enc_batch_extend_vocab)\n","\n","    extra_zeros = None\n","    if batch.max_art_oovs > 0:\n","        extra_zeros = T.zeros(batch_size, batch.max_art_oovs)\n","        extra_zeros = get_cuda(extra_zeros)\n","\n","\n","    return enc_batch, enc_lens, enc_padding_mask, enc_batch_extend_vocab, extra_zeros, ct_e\n","\n","\n","def get_dec_data(batch):\n","    dec_batch = T.from_numpy(batch.dec_batch).long()\n","    dec_lens = batch.dec_lens\n","    max_dec_len = np.max(dec_lens)\n","    dec_lens = T.from_numpy(batch.dec_lens).float()\n","\n","    target_batch = T.from_numpy(batch.target_batch).long()\n","\n","    dec_batch = get_cuda(dec_batch)\n","    dec_lens = get_cuda(dec_lens)\n","    target_batch = get_cuda(target_batch)\n","\n","    return dec_batch, max_dec_len, dec_lens, target_batch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VpxpsuZAI993","colab_type":"text"},"source":["#8. Training (ROUGE reward function for RL training)"]},{"cell_type":"code","metadata":{"id":"XfiBrvBrmnB5","colab_type":"code","colab":{}},"source":["random.seed(123)\n","T.manual_seed(123)\n","if T.cuda.is_available():\n","    T.cuda.manual_seed_all(123)\n","\n","class Train(object):\n","    def __init__(self, opt):\n","        self.vocab = Vocab(vocab_path, vocab_size)\n","        self.batcher = Batcher(train_data_path, self.vocab, mode='train',\n","                               batch_size=batch_size, single_pass=False)            #config\n","        self.opt = opt\n","        self.start_id = self.vocab.word2id(START_DECODING)          #data.\n","        self.end_id = self.vocab.word2id(STOP_DECODING)\n","        self.pad_id = self.vocab.word2id(PAD_TOKEN)\n","        self.unk_id = self.vocab.word2id(UNKNOWN_TOKEN)\n","        time.sleep(5)\n","\n","    def save_model(self, iter):\n","        save_path = new_save_model_path + \"/%07d.tar\" % iter\n","        T.save({\n","            \"iter\": iter + 1,\n","            \"model_dict\": self.model.state_dict(),\n","            \"trainer_dict\": self.trainer.state_dict()\n","        }, save_path)\n","\n","    def setup_train(self):\n","        self.model = Model()\n","        self.model = get_cuda(self.model)\n","        self.trainer = T.optim.Adam(self.model.parameters(), lr=lr)\n","        start_iter = 0\n","        if self.opt.load_model is not None:\n","            load_model_path = os.path.join(save_model_path, self.opt.load_model)\n","            checkpoint = T.load(load_model_path)\n","            start_iter = checkpoint[\"iter\"]\n","            self.model.load_state_dict(checkpoint[\"model_dict\"])\n","            self.trainer.load_state_dict(checkpoint[\"trainer_dict\"])\n","            print(\"Loaded model at \" + load_model_path)\n","        if self.opt.new_lr is not None:\n","            self.trainer = T.optim.Adam(self.model.parameters(), lr=self.opt.new_lr)\n","        return start_iter\n","\n","    def train_batch_MLE(self, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, batch):\n","        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n","                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n","        Args:\n","        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n","        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n","        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n","        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n","        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n","        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n","        :param batch: batch object\n","        '''\n","        dec_batch, max_dec_len, dec_lens, target_batch = get_dec_data(batch)                        #Get input and target batchs for training decoder\n","        step_losses = []\n","        s_t = (enc_hidden[0], enc_hidden[1])                                                        #Decoder hidden states\n","        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(self.start_id))                             #Input to the decoder\n","        prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n","        sum_temporal_srcs = None                                                                    #Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n","        for t in range(min(max_dec_len, max_dec_steps)):\n","            use_gound_truth = get_cuda((T.rand(len(enc_out)) > 0.25)).long()                        #Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n","            x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t                   #Select decoder input based on use_ground_truth probabilities\n","            x_t = self.model.embeds(x_t)\n","            final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = self.model.decoder(x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n","            target = target_batch[:, t]\n","            log_probs = T.log(final_dist + eps)\n","            step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=self.pad_id)\n","            step_losses.append(step_loss)\n","            x_t = T.multinomial(final_dist, 1).squeeze()                                            #Sample words from final distribution which can be used as input in next time step\n","            is_oov = (x_t >= vocab_size).long()                                              #Mask indicating whether sampled word is OOV\n","            x_t = (1 - is_oov) * x_t.detach() + (is_oov) * self.unk_id                              #Replace OOVs with [UNK] token\n","\n","        losses = T.sum(T.stack(step_losses, 1), 1)                                                  #unnormalized losses for each example in the batch; (batch_size)\n","        batch_avg_loss = losses / dec_lens                                                          #Normalized losses; (batch_size)\n","        mle_loss = T.mean(batch_avg_loss)                                                           #Average batch loss\n","        return mle_loss\n","\n","    def train_batch_RL(self, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, article_oovs, greedy):\n","        '''Generate sentences from decoder entirely using sampled tokens as input. These sentences are used for ROUGE evaluation\n","        Args\n","        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n","        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n","        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n","        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n","        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n","        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n","        :param article_oovs: Batch containing list of OOVs in each example\n","        :param greedy: If true, performs greedy based sampling, else performs multinomial sampling\n","        Returns:\n","        :decoded_strs: List of decoded sentences\n","        :log_probs: Log probabilities of sampled words\n","        '''\n","        s_t = enc_hidden                                                                            #Decoder hidden states\n","        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(self.start_id))                             #Input to the decoder\n","        prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n","        sum_temporal_srcs = None                                                                    #Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n","        inds = []                                                                                   #Stores sampled indices for each time step\n","        decoder_padding_mask = []                                                                   #Stores padding masks of generated samples\n","        log_probs = []                                                                              #Stores log probabilites of generated samples\n","        mask = get_cuda(T.LongTensor(len(enc_out)).fill_(1))                                        #Values that indicate whether [STOP] token has already been encountered; 1 => Not encountered, 0 otherwise\n","\n","        for t in range(max_dec_steps):\n","            x_t = self.model.embeds(x_t)\n","            probs, s_t, ct_e, sum_temporal_srcs, prev_s = self.model.decoder(x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n","            if greedy is False:\n","                multi_dist = Categorical(probs)\n","                x_t = multi_dist.sample()                                                           #perform multinomial sampling\n","                log_prob = multi_dist.log_prob(x_t)\n","                log_probs.append(log_prob)\n","            else:\n","                _, x_t = T.max(probs, dim=1)                                                        #perform greedy sampling\n","            x_t = x_t.detach()\n","            inds.append(x_t)\n","            mask_t = get_cuda(T.zeros(len(enc_out)))                                                #Padding mask of batch for current time step\n","            mask_t[mask == 1] = 1                                                                   #If [STOP] is not encountered till previous time step, mask_t = 1 else mask_t = 0\n","            mask[(mask == 1) + (x_t == self.end_id) == 2] = 0                                       #If [STOP] is not encountered till previous time step and current word is [STOP], make mask = 0\n","            decoder_padding_mask.append(mask_t)\n","            is_oov = (x_t>=vocab_size).long()                                                #Mask indicating whether sampled word is OOV\n","            x_t = (1-is_oov)*x_t + (is_oov)*self.unk_id                                             #Replace OOVs with [UNK] token\n","\n","        inds = T.stack(inds, dim=1)\n","        decoder_padding_mask = T.stack(decoder_padding_mask, dim=1)\n","        if greedy is False:                                                                         #If multinomial based sampling, compute log probabilites of sampled words\n","            log_probs = T.stack(log_probs, dim=1)\n","            log_probs = log_probs * decoder_padding_mask                                            #Not considering sampled words with padding mask = 0\n","            lens = T.sum(decoder_padding_mask, dim=1)                                               #Length of sampled sentence\n","            log_probs = T.sum(log_probs, dim=1) / lens  # (bs,)                                     #compute normalizied log probability of a sentence\n","        decoded_strs = []\n","        for i in range(len(enc_out)):\n","            id_list = inds[i].cpu().numpy()\n","            oovs = article_oovs[i]\n","            S = outputids2words(id_list, self.vocab, oovs)                                     #Generate sentence corresponding to sampled words\n","            try:\n","                end_idx = S.index(STOP_DECODING)\n","                S = S[:end_idx]\n","            except ValueError:\n","                S = S\n","            if len(S) < 2:                                                                           #If length of sentence is less than 2 words, replace it with \"xxx\"; Avoids setences like \".\" which throws error while calculating ROUGE\n","                S = [\"xxx\"]\n","            S = \" \".join(S)\n","            decoded_strs.append(S)\n","\n","        return decoded_strs, log_probs\n","\n","    def reward_function(self, decoded_sents, original_sents):\n","        rouge = Rouge()\n","        try:\n","            scores = rouge.get_scores(decoded_sents, original_sents)\n","        except Exception:\n","            print(\"Rouge failed for multi sentence evaluation.. Finding exact pair\")\n","            scores = []\n","            for i in range(len(decoded_sents)):\n","                try:\n","                    score = rouge.get_scores(decoded_sents[i], original_sents[i])\n","                except Exception:\n","                    print(\"Error occured at:\")\n","                    print(\"decoded_sents:\", decoded_sents[i])\n","                    print(\"original_sents:\", original_sents[i])\n","                    score = [{\"rouge-l\":{\"f\":0.0}}]\n","                scores.append(score[0])\n","        rouge_l_f1 = [score[\"rouge-l\"][\"f\"] for score in scores]\n","        rouge_l_f1 = get_cuda(T.FloatTensor(rouge_l_f1))\n","        return rouge_l_f1\n","\n","    # def write_to_file(self, decoded, max, original, sample_r, baseline_r, iter):\n","    #     with open(\"temp.txt\", \"w\") as f:\n","    #         f.write(\"iter:\"+str(iter)+\"\\n\")\n","    #         for i in range(len(original)):\n","    #             f.write(\"dec: \"+decoded[i]+\"\\n\")\n","    #             f.write(\"max: \"+max[i]+\"\\n\")\n","    #             f.write(\"org: \"+original[i]+\"\\n\")\n","    #             f.write(\"Sample_R: %.4f, Baseline_R: %.4f\\n\\n\"%(sample_r[i].item(), baseline_r[i].item()))\n","\n","\n","    def train_one_batch(self, batch, iter):\n","        enc_batch, enc_lens, enc_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n","\n","        enc_batch = self.model.embeds(enc_batch)                                                    #Get embeddings for encoder input\n","        enc_out, enc_hidden = self.model.encoder(enc_batch, enc_lens)\n","\n","        # -------------------------------Summarization-----------------------\n","        if self.opt.train_mle == \"yes\":                                                             #perform MLE training\n","            mle_loss = self.train_batch_MLE(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, batch)\n","        else:\n","            mle_loss = get_cuda(T.FloatTensor([0]))\n","        # --------------RL training-----------------------------------------------------\n","        if self.opt.train_rl == \"yes\":                                                              #perform reinforcement learning training\n","            # multinomial sampling\n","            sample_sents, RL_log_probs = self.train_batch_RL(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, batch.art_oovs, greedy=False)\n","            with T.autograd.no_grad():\n","                # greedy sampling\n","                greedy_sents, _ = self.train_batch_RL(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, batch.art_oovs, greedy=True)\n","\n","            sample_reward = self.reward_function(sample_sents, batch.original_abstracts)\n","            baseline_reward = self.reward_function(greedy_sents, batch.original_abstracts)\n","            # if iter%200 == 0:\n","            #     self.write_to_file(sample_sents, greedy_sents, batch.original_abstracts, sample_reward, baseline_reward, iter)\n","            rl_loss = -(sample_reward - baseline_reward) * RL_log_probs                             #Self-critic policy gradient training (eq 15 in https://arxiv.org/pdf/1705.04304.pdf)\n","            rl_loss = T.mean(rl_loss)\n","\n","            batch_reward = T.mean(sample_reward).item()\n","        else:\n","            rl_loss = get_cuda(T.FloatTensor([0]))\n","            batch_reward = 0\n","\n","    # ------------------------------------------------------------------------------------\n","        self.trainer.zero_grad()\n","        (self.opt.mle_weight * mle_loss + self.opt.rl_weight * rl_loss).backward()\n","        self.trainer.step()\n","\n","        return mle_loss.item(), batch_reward\n","\n","    def trainIters(self):                                       #training step\n","        iter = self.setup_train()\n","        count = mle_total = r_total = 0\n","        while iter <= max_iterations:\n","            batch = self.batcher.next_batch()\n","            try:\n","                mle_loss, r = self.train_one_batch(batch, iter)\n","            except KeyboardInterrupt:\n","                print(\"-------------------Keyboard Interrupt------------------\")\n","                sys.exit\n","\n","            mle_total += mle_loss\n","            r_total += r\n","            count += 1\n","            iter += 1\n","\n","            if iter % 200 == 0:\n","                mle_avg = mle_total / count\n","                r_avg = r_total / count\n","                print(\"iter:\", iter, \"mle_loss:\", \"%.3f\" % mle_avg, \"reward:\", \"%.4f\" % r_avg)\n","                count = mle_total = r_total = 0\n","\n","            if iter % 1000 == 0:\n","                self.save_model(iter)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TU9eAzeYelbn","colab_type":"text"},"source":["#9. Training (BERTScore)"]},{"cell_type":"code","metadata":{"id":"E4ZCdSkggH4r","colab_type":"code","colab":{}},"source":["import os\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"    #Set cuda device\n","import sys\n","import time\n","import gc\n","\n","import torch as T\n","import torch.nn as nn\n","import torch.nn.functional as F\n","#from model import Model\n","\n","#from data_util import config, data\n","#from data_util.batcher import Batcher\n","#from data_util.data import Vocab\n","#from train_util import *\n","from torch.distributions import Categorical\n","import bert_score\n","#from rouge import Rouge\n","from numpy import random\n","import argparse\n","\n","random.seed(123)\n","T.manual_seed(123)\n","if T.cuda.is_available():\n","    T.cuda.manual_seed_all(123)\n","\n","class Train(object):\n","    def __init__(self, opt):\n","        self.vocab = Vocab(vocab_path, vocab_size)\n","        self.batcher = Batcher(train_data_path, self.vocab, mode='train',\n","                               batch_size=batch_size, single_pass=False)            #config\n","        self.opt = opt\n","        self.start_id = self.vocab.word2id(START_DECODING)          #data.\n","        self.end_id = self.vocab.word2id(STOP_DECODING)\n","        self.pad_id = self.vocab.word2id(PAD_TOKEN)\n","        self.unk_id = self.vocab.word2id(UNKNOWN_TOKEN)\n","        time.sleep(5)\n","\n","    def save_model(self, iter):\n","        save_path = new_save_model_path + \"/%07d.tar\" % iter\n","        T.save({\n","            \"iter\": iter + 1,\n","            \"model_dict\": self.model.state_dict(),\n","            \"trainer_dict\": self.trainer.state_dict()\n","        }, save_path)\n","\n","    def setup_train(self):\n","        self.model = Model()\n","        self.model = get_cuda(self.model)\n","        self.trainer = T.optim.Adam(self.model.parameters(), lr=lr)\n","        start_iter = 0\n","        if self.opt.load_model is not None:\n","            load_model_path = os.path.join(save_model_path, self.opt.load_model)\n","            checkpoint = T.load(load_model_path)\n","            start_iter = checkpoint[\"iter\"]\n","            self.model.load_state_dict(checkpoint[\"model_dict\"])\n","            self.trainer.load_state_dict(checkpoint[\"trainer_dict\"])\n","            print(\"Loaded model at \" + load_model_path)\n","        if self.opt.new_lr is not None:\n","            self.trainer = T.optim.Adam(self.model.parameters(), lr=self.opt.new_lr)\n","        return start_iter\n","\n","    def train_batch_MLE(self, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, batch):\n","        ''' Calculate Negative Log Likelihood Loss for the given batch. In order to reduce exposure bias,\n","                pass the previous generated token as input with a probability of 0.25 instead of ground truth label\n","        Args:\n","        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n","        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n","        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n","        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n","        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n","        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n","        :param batch: batch object\n","        '''\n","        dec_batch, max_dec_len, dec_lens, target_batch = get_dec_data(batch)                        #Get input and target batchs for training decoder\n","        step_losses = []\n","        s_t = (enc_hidden[0], enc_hidden[1])                                                        #Decoder hidden states\n","        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(self.start_id))                             #Input to the decoder\n","        prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n","        sum_temporal_srcs = None                                                                    #Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n","        for t in range(min(max_dec_len, max_dec_steps)):\n","            #use_gound_truth = get_cuda((T.rand(len(enc_out)) > 0.25)).long()                        #Probabilities indicating whether to use ground truth labels instead of previous decoded tokens\n","            #x_t = use_gound_truth * dec_batch[:, t] + (1 - use_gound_truth) * x_t                   #Select decoder input based on use_ground_truth probabilities\n","            x_t = dec_batch[:, t]       #here we use purely ML\n","\n","            x_t = self.model.embeds(x_t)\n","            final_dist, s_t, ct_e, sum_temporal_srcs, prev_s = self.model.decoder(x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n","            target = target_batch[:, t]\n","            log_probs = T.log(final_dist + eps)\n","            step_loss = F.nll_loss(log_probs, target, reduction=\"none\", ignore_index=self.pad_id)\n","            step_losses.append(step_loss)\n","            x_t = T.multinomial(final_dist, 1).squeeze()                                            #Sample words from final distribution which can be used as input in next time step\n","            is_oov = (x_t >= vocab_size).long()                                              #Mask indicating whether sampled word is OOV\n","            x_t = (1 - is_oov) * x_t.detach() + (is_oov) * self.unk_id                              #Replace OOVs with [UNK] token\n","\n","        losses = T.sum(T.stack(step_losses, 1), 1)                                                  #unnormalized losses for each example in the batch; (batch_size)\n","        batch_avg_loss = losses / dec_lens                                                          #Normalized losses; (batch_size)\n","        mle_loss = T.mean(batch_avg_loss)                                                           #Average batch loss\n","        return mle_loss\n","\n","    def train_batch_RL(self, enc_out, enc_hidden, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, article_oovs, greedy):\n","        '''Generate sentences from decoder entirely using sampled tokens as input. These sentences are used for ROUGE evaluation\n","        Args\n","        :param enc_out: Outputs of the encoder for all time steps (batch_size, length_input_sequence, 2*hidden_size)\n","        :param enc_hidden: Tuple containing final hidden state & cell state of encoder. Shape of h & c: (batch_size, hidden_size)\n","        :param enc_padding_mask: Mask for encoder input; Tensor of size (batch_size, length_input_sequence) with values of 0 for pad tokens & 1 for others\n","        :param ct_e: encoder context vector for time_step=0 (eq 5 in https://arxiv.org/pdf/1705.04304.pdf)\n","        :param extra_zeros: Tensor used to extend vocab distribution for pointer mechanism\n","        :param enc_batch_extend_vocab: Input batch that stores OOV ids\n","        :param article_oovs: Batch containing list of OOVs in each example\n","        :param greedy: If true, performs greedy based sampling, else performs multinomial sampling\n","        Returns:\n","        :decoded_strs: List of decoded sentences\n","        :log_probs: Log probabilities of sampled words\n","        '''\n","        s_t = enc_hidden                                                                            #Decoder hidden states\n","        x_t = get_cuda(T.LongTensor(len(enc_out)).fill_(self.start_id))                             #Input to the decoder\n","        prev_s = None                                                                               #Used for intra-decoder attention (section 2.2 in https://arxiv.org/pdf/1705.04304.pdf)\n","        sum_temporal_srcs = None                                                                    #Used for intra-temporal attention (section 2.1 in https://arxiv.org/pdf/1705.04304.pdf)\n","        inds = []                                                                                   #Stores sampled indices for each time step\n","        decoder_padding_mask = []                                                                   #Stores padding masks of generated samples\n","        log_probs = []                                                                              #Stores log probabilites of generated samples\n","        mask = get_cuda(T.LongTensor(len(enc_out)).fill_(1))                                        #Values that indicate whether [STOP] token has already been encountered; 1 => Not encountered, 0 otherwise\n","\n","        for t in range(max_dec_steps):\n","            x_t = self.model.embeds(x_t)\n","            probs, s_t, ct_e, sum_temporal_srcs, prev_s = self.model.decoder(x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s)\n","            if greedy is False:\n","                multi_dist = Categorical(probs)\n","                x_t = multi_dist.sample()                                                           #perform multinomial sampling\n","                log_prob = multi_dist.log_prob(x_t)\n","                log_probs.append(log_prob)\n","            else:\n","                _, x_t = T.max(probs, dim=1)                                                        #perform greedy sampling\n","            x_t = x_t.detach()\n","            inds.append(x_t)\n","            mask_t = get_cuda(T.zeros(len(enc_out)))                                                #Padding mask of batch for current time step\n","            mask_t[mask == 1] = 1                                                                   #If [STOP] is not encountered till previous time step, mask_t = 1 else mask_t = 0\n","            mask[(mask == 1) + (x_t == self.end_id) == 2] = 0                                       #If [STOP] is not encountered till previous time step and current word is [STOP], make mask = 0\n","            decoder_padding_mask.append(mask_t)\n","            is_oov = (x_t>=vocab_size).long()                                                #Mask indicating whether sampled word is OOV\n","            x_t = (1-is_oov)*x_t + (is_oov)*self.unk_id                                             #Replace OOVs with [UNK] token\n","\n","        inds = T.stack(inds, dim=1)\n","        decoder_padding_mask = T.stack(decoder_padding_mask, dim=1)\n","        if greedy is False:                                                                         #If multinomial based sampling, compute log probabilites of sampled words\n","            log_probs = T.stack(log_probs, dim=1)\n","            log_probs = log_probs * decoder_padding_mask                                            #Not considering sampled words with padding mask = 0\n","            lens = T.sum(decoder_padding_mask, dim=1)                                               #Length of sampled sentence\n","            log_probs = T.sum(log_probs, dim=1) / lens  # (bs,)                                     #compute normalizied log probability of a sentence\n","        decoded_strs = []\n","        for i in range(len(enc_out)):\n","            id_list = inds[i].cpu().numpy()\n","            oovs = article_oovs[i]\n","            S = outputids2words(id_list, self.vocab, oovs)                                     #Generate sentence corresponding to sampled words\n","            try:\n","                end_idx = S.index(STOP_DECODING)\n","                S = S[:end_idx]\n","            except ValueError:\n","                S = S\n","            if len(S) < 2:                                                                           #If length of sentence is less than 2 words, replace it with \"xxx\"; Avoids setences like \".\" which throws error while calculating ROUGE\n","                S = [\"xxx\"]\n","            S = \" \".join(S)\n","            decoded_strs.append(S)\n","\n","        return decoded_strs, log_probs\n","\n","    def reward_function(self, decoded_sents, original_sents):\n","        #rouge = Rouge()\n","\n","        _,_,scores = bert_score.score(decoded_sents, original_sents, lang = 'en', verbose = False, batch_size = 50)\n","        gc.collect()\n","\n","\n","            #scores = T.tensor([0.])\n","            #for i in range(len(decoded_sents)):\n","             #   print('processing {}th reward...'.format(i+1))\n","              #  _,_, score = bert_score.score([decoded_sents[i]], [original_sents[i]], lang = 'en', verbose = False)\n","               # scores = scores + score\n","                #gc.collect()\n","        bertscore_f = get_cuda(scores)\n","        #bertscore_f = get_cuda(scores/len(decoded_sents))          #the return of bert-score.score is a tensor, \n","                                               #Each Tensor has the same number of items with the candidate and reference lists. \n","        print('pass reward function')                                        #Each item in the list is a scalar, representing the score for the corresponding candidates and references.\n","        return bertscore_f\n","\n","\n","    # def write_to_file(self, decoded, max, original, sample_r, baseline_r, iter):\n","    #     with open(\"temp.txt\", \"w\") as f:\n","    #         f.write(\"iter:\"+str(iter)+\"\\n\")\n","    #         for i in range(len(original)):\n","    #             f.write(\"dec: \"+decoded[i]+\"\\n\")\n","    #             f.write(\"max: \"+max[i]+\"\\n\")\n","    #             f.write(\"org: \"+original[i]+\"\\n\")\n","    #             f.write(\"Sample_R: %.4f, Baseline_R: %.4f\\n\\n\"%(sample_r[i].item(), baseline_r[i].item()))\n","\n","\n","    def train_one_batch(self, batch, iter):\n","        enc_batch, enc_lens, enc_padding_mask, enc_batch_extend_vocab, extra_zeros, context = get_enc_data(batch)\n","\n","        enc_batch = self.model.embeds(enc_batch)                                                    #Get embeddings for encoder input\n","        enc_out, enc_hidden = self.model.encoder(enc_batch, enc_lens)\n","\n","        # -------------------------------Summarization-----------------------\n","        if self.opt.train_mle == \"yes\":                                                             #perform MLE training\n","            mle_loss = self.train_batch_MLE(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, batch)\n","        else:\n","            mle_loss = get_cuda(T.FloatTensor([0]))\n","        # --------------RL training-----------------------------------------------------\n","        if self.opt.train_rl == \"yes\":                                                              #perform reinforcement learning training\n","            # multinomial sampling\n","            sample_sents, RL_log_probs = self.train_batch_RL(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, batch.art_oovs, greedy=False)\n","            with T.autograd.no_grad():\n","                # greedy sampling\n","                greedy_sents, _ = self.train_batch_RL(enc_out, enc_hidden, enc_padding_mask, context, extra_zeros, enc_batch_extend_vocab, batch.art_oovs, greedy=True)\n","\n","            sample_reward = self.reward_function(sample_sents, batch.original_abstracts)\n","            baseline_reward = self.reward_function(greedy_sents, batch.original_abstracts)\n","            # if iter%200 == 0:\n","            #     self.write_to_file(sample_sents, greedy_sents, batch.original_abstracts, sample_reward, baseline_reward, iter)\n","            rl_loss = -(sample_reward - baseline_reward) * RL_log_probs                             #Self-critic policy gradient training (eq 15 in https://arxiv.org/pdf/1705.04304.pdf)\n","            rl_loss = T.mean(rl_loss)\n","\n","            batch_reward = T.mean(sample_reward).item()\n","        else:\n","            rl_loss = get_cuda(T.FloatTensor([0]))\n","            batch_reward = 0\n","\n","    # ------------------------------------------------------------------------------------\n","        self.trainer.zero_grad()\n","        (self.opt.mle_weight * mle_loss + self.opt.rl_weight * rl_loss).backward()\n","        self.trainer.step()\n","\n","        return mle_loss.item(), batch_reward\n","\n","    def trainIters(self):                                       #training step\n","        iter = self.setup_train()\n","        count = mle_total = r_total = 0\n","        reward_list = []\n","        while iter <= max_iterations:\n","            batch = self.batcher.next_batch()\n","            try:\n","                mle_loss, r = self.train_one_batch(batch, iter)\n","            except KeyboardInterrupt:\n","                print(\"-------------------Keyboard Interrupt------------------\")\n","                sys.exit()\n","\n","            mle_total += mle_loss\n","            r_total += r\n","            count += 1\n","            iter += 1\n","\n","            mle_avg = mle_total / count\n","            r_avg = r_total / count\n","            print(\"iter:\", iter, \"mle_loss:\", \"%.3f\" % mle_avg, \"reward:\", \"%.4f\" % r_avg)\n","            count = mle_total = r_total = 0\n","\n","            reward_list.append(r_avg)\n","\n","            if iter % 100 == 0:\n","                self.save_model(iter)\n","        return reward_list\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LH0Nipo-Jtmz","colab_type":"text"},"source":["#10.Beam search"]},{"cell_type":"code","metadata":{"id":"5Hm6v1pDmnEN","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch as T\n","\n","\n","class Beam(object):\n","    def __init__(self, start_id, end_id, unk_id, hidden_state, context):\n","        h,c = hidden_state                                              #(n_hid,)\n","        self.tokens = T.LongTensor(beam_size,1).fill_(start_id)  #(beam, t) after t time steps\n","        self.scores = T.FloatTensor(beam_size,1).fill_(-30)      #beam,1; Initial score of beams = -30\n","        self.tokens, self.scores = get_cuda(self.tokens), get_cuda(self.scores)\n","        self.scores[0][0] = 0                                           #At time step t=0, all beams should extend from a single beam. So, I am giving high initial score to 1st beam\n","        self.hid_h = h.unsqueeze(0).repeat(beam_size, 1)         #beam, n_hid\n","        self.hid_c = c.unsqueeze(0).repeat(beam_size, 1)         #beam, n_hid\n","        self.context = context.unsqueeze(0).repeat(beam_size, 1) #beam, 2*n_hid\n","        self.sum_temporal_srcs = None\n","        self.prev_s = None\n","        self.done = False\n","        self.end_id = end_id\n","        self.unk_id = unk_id\n","\n","    def get_current_state(self):\n","        tokens = self.tokens[:,-1].clone()\n","        for i in range(len(tokens)):\n","            if tokens[i].item() >= vocab_size:\n","                tokens[i] = self.unk_id\n","        return tokens\n","\n","\n","    def advance(self, prob_dist, hidden_state, context, sum_temporal_srcs, prev_s):\n","        '''Perform beam search: Considering the probabilites of given n_beam x n_extended_vocab words, select first n_beam words that give high total scores\n","        :param prob_dist: (beam, n_extended_vocab)\n","        :param hidden_state: Tuple of (beam, n_hid) tensors\n","        :param context:   (beam, 2*n_hidden)\n","        :param sum_temporal_srcs:   (beam, n_seq)\n","        :param prev_s:  (beam, t, n_hid)\n","        '''\n","        n_extended_vocab = prob_dist.size(1)\n","        h, c = hidden_state\n","        log_probs = T.log(prob_dist+eps)                         #beam, n_extended_vocab\n","\n","        scores = log_probs + self.scores                                #beam, n_extended_vocab\n","        scores = scores.view(-1,1)                                      #beam*n_extended_vocab, 1\n","        best_scores, best_scores_id = T.topk(input=scores, k=beam_size, dim=0)   #will be sorted in descending order of scores\n","        self.scores = best_scores                                       #(beam,1); sorted\n","        beams_order = best_scores_id.squeeze(1)/n_extended_vocab        #(beam,); sorted\n","        best_words = best_scores_id%n_extended_vocab                    #(beam,1); sorted\n","        self.hid_h = h[beams_order]                                     #(beam, n_hid); sorted\n","        self.hid_c = c[beams_order]                                     #(beam, n_hid); sorted\n","        self.context = context[beams_order]\n","        if sum_temporal_srcs is not None:\n","            self.sum_temporal_srcs = sum_temporal_srcs[beams_order]     #(beam, n_seq); sorted\n","        if prev_s is not None:\n","            self.prev_s = prev_s[beams_order]                           #(beam, t, n_hid); sorted\n","        self.tokens = self.tokens[beams_order]                          #(beam, t); sorted\n","        self.tokens = T.cat([self.tokens, best_words], dim=1)           #(beam, t+1); sorted\n","\n","        #End condition is when top-of-beam is EOS.\n","        if best_words[0][0] == self.end_id:\n","            self.done = True\n","\n","    def get_best(self):\n","        best_token = self.tokens[0].cpu().numpy().tolist()              #Since beams are always in sorted (descending) order, 1st beam is the best beam\n","        try:\n","            end_idx = best_token.index(self.end_id)\n","        except ValueError:\n","            end_idx = len(best_token)\n","        best_token = best_token[1:end_idx]\n","        return best_token\n","\n","    def get_all(self):\n","        all_tokens = []\n","        for i in range(len(self.tokens)):\n","            all_tokens.append(self.tokens[i].cpu().numpy())\n","        return all_tokens\n","\n","\n","def beam_search(enc_hid, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, model, start_id, end_id, unk_id):\n","\n","    batch_size = len(enc_hid[0])\n","    beam_idx = T.LongTensor(list(range(batch_size)))\n","    beams = [Beam(start_id, end_id, unk_id, (enc_hid[0][i], enc_hid[1][i]), ct_e[i]) for i in range(batch_size)]   #For each example in batch, create Beam object\n","    n_rem = batch_size                                                  #Index of beams that are active, i.e: didn't generate [STOP] yet\n","    sum_temporal_srcs = None                                            #Number of examples in batch that didn't generate [STOP] yet\n","    prev_s = None\n","\n","    for t in range(max_dec_steps):\n","        x_t = T.stack(\n","            [beam.get_current_state() for beam in beams if beam.done == False]      #remaining(rem),beam\n","        ).contiguous().view(-1)                                                     #(rem*beam,)\n","        x_t = model.embeds(x_t)                                                 #rem*beam, n_emb\n","\n","        dec_h = T.stack(\n","            [beam.hid_h for beam in beams if beam.done == False]                    #rem*beam,n_hid\n","        ).contiguous().view(-1,hidden_dim)\n","        dec_c = T.stack(\n","            [beam.hid_c for beam in beams if beam.done == False]                    #rem,beam,n_hid\n","        ).contiguous().view(-1,hidden_dim)                                   #rem*beam,n_hid\n","\n","        ct_e = T.stack(\n","            [beam.context for beam in beams if beam.done == False]                  #rem,beam,n_hid\n","        ).contiguous().view(-1,2*hidden_dim)                                 #rem,beam,n_hid\n","\n","        if sum_temporal_srcs is not None:\n","            sum_temporal_srcs = T.stack(\n","                [beam.sum_temporal_srcs for beam in beams if beam.done == False]\n","            ).contiguous().view(-1, enc_out.size(1))                                #rem*beam, n_seq\n","\n","        if prev_s is not None:\n","            prev_s = T.stack(\n","                [beam.prev_s for beam in beams if beam.done == False]\n","            ).contiguous().view(-1, t, hidden_dim)                           #rem*beam, t-1, n_hid\n","\n","\n","        s_t = (dec_h, dec_c)\n","        enc_out_beam = enc_out[beam_idx].view(n_rem,-1).repeat(1, beam_size).view(-1, enc_out.size(1), enc_out.size(2))\n","        enc_pad_mask_beam = enc_padding_mask[beam_idx].repeat(1, beam_size).view(-1, enc_padding_mask.size(1))\n","\n","        extra_zeros_beam = None\n","        if extra_zeros is not None:\n","            extra_zeros_beam = extra_zeros[beam_idx].repeat(1, beam_size).view(-1, extra_zeros.size(1))\n","        enc_extend_vocab_beam = enc_batch_extend_vocab[beam_idx].repeat(1, beam_size).view(-1, enc_batch_extend_vocab.size(1))\n","\n","        final_dist, (dec_h, dec_c), ct_e, sum_temporal_srcs, prev_s = model.decoder(x_t, s_t, enc_out_beam, enc_pad_mask_beam, ct_e, extra_zeros_beam, enc_extend_vocab_beam, sum_temporal_srcs, prev_s)              #final_dist: rem*beam, n_extended_vocab\n","\n","        final_dist = final_dist.view(n_rem, beam_size, -1)                   #final_dist: rem, beam, n_extended_vocab\n","        dec_h = dec_h.view(n_rem, beam_size, -1)                             #rem, beam, n_hid\n","        dec_c = dec_c.view(n_rem, beam_size, -1)                             #rem, beam, n_hid\n","        ct_e = ct_e.view(n_rem, beam_size, -1)                             #rem, beam, 2*n_hid\n","\n","        if sum_temporal_srcs is not None:\n","            sum_temporal_srcs = sum_temporal_srcs.view(n_rem, beam_size, -1) #rem, beam, n_seq\n","\n","        if prev_s is not None:\n","            prev_s = prev_s.view(n_rem, beam_size, -1, hidden_dim)    #rem, beam, t\n","\n","        # For all the active beams, perform beam search\n","        active = []         #indices of active beams after beam search\n","\n","        for i in range(n_rem):\n","            b = beam_idx[i].item()\n","            beam = beams[b]\n","            if beam.done:\n","                continue\n","\n","            sum_temporal_srcs_i = prev_s_i = None\n","            if sum_temporal_srcs is not None:\n","                sum_temporal_srcs_i = sum_temporal_srcs[i]                              #beam, n_seq\n","            if prev_s is not None:\n","                prev_s_i = prev_s[i]                                                #beam, t, n_hid\n","            beam.advance(final_dist[i], (dec_h[i], dec_c[i]), ct_e[i], sum_temporal_srcs_i, prev_s_i)\n","            if beam.done == False:\n","                active.append(b)\n","\n","        if len(active) == 0:\n","            break\n","\n","        beam_idx = T.LongTensor(active)\n","        n_rem = len(beam_idx)\n","\n","    predicted_words = []\n","    for beam in beams:\n","        predicted_words.append(beam.get_best())\n","\n","    return predicted_words"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XPsbfVYEKx2U","colab_type":"text"},"source":["#11. Evaluation and testing class using ROUGE"]},{"cell_type":"code","metadata":{"id":"tWY3iI84Jva2","colab_type":"code","colab":{}},"source":["'''\n","import os\n","\n","import time\n","\n","import torch as T\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","from rouge import Rouge\n","import argparse\n","'''\n","\n","def get_cuda(tensor):\n","    if T.cuda.is_available():\n","        tensor = tensor.cuda()\n","    return tensor\n","\n","class Evaluate(object):\n","    def __init__(self, data_path, opt, batch_size = batch_size):\n","        self.vocab = Vocab(vocab_path, vocab_size)\n","        self.batcher = Batcher(data_path, self.vocab, mode='eval',\n","                               batch_size=batch_size, single_pass=True)\n","        self.opt = opt\n","        time.sleep(5)\n","\n","    def setup_valid(self):\n","        self.model = Model()\n","        self.model = get_cuda(self.model)\n","        checkpoint = T.load(os.path.join(save_model_path, self.opt.load_model))\n","        self.model.load_state_dict(checkpoint[\"model_dict\"])\n","\n","\n","    def print_original_predicted(self, decoded_sents, ref_sents, article_sents, loadfile):\n","        filename = \"test_\"+loadfile.split(\".\")[0]+\".txt\"\n","    \n","        with open(os.path.join(save_example_path,filename), \"w\") as f:\n","            for i in range(len(decoded_sents)):\n","                f.write(\"article: \"+article_sents[i] + \"\\n\")\n","                f.write(\"ref: \" + ref_sents[i] + \"\\n\")\n","                f.write(\"dec: \" + decoded_sents[i] + \"\\n\\n\")\n","\n","    def evaluate_batch(self, print_sents = False):\n","\n","        self.setup_valid()\n","        batch = self.batcher.next_batch()\n","        start_id = self.vocab.word2id(START_DECODING)\n","        end_id = self.vocab.word2id(STOP_DECODING)\n","        unk_id = self.vocab.word2id(UNKNOWN_TOKEN)\n","        decoded_sents = []\n","        ref_sents = []\n","        article_sents = []\n","        rouge = Rouge()\n","        while batch is not None:\n","            enc_batch, enc_lens, enc_padding_mask, enc_batch_extend_vocab, extra_zeros, ct_e = get_enc_data(batch)\n","\n","            with T.autograd.no_grad():\n","                enc_batch = self.model.embeds(enc_batch)\n","                enc_out, enc_hidden = self.model.encoder(enc_batch, enc_lens)\n","\n","            #-----------------------Summarization----------------------------------------------------\n","            with T.autograd.no_grad():\n","                pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, self.model, start_id, end_id, unk_id)\n","\n","            for i in range(len(pred_ids)):\n","                decoded_words = outputids2words(pred_ids[i], self.vocab, batch.art_oovs[i])\n","                if len(decoded_words) < 2:\n","                    decoded_words = \"xxx\"\n","                else:\n","                    decoded_words = \" \".join(decoded_words)\n","                decoded_sents.append(decoded_words)\n","                abstract = batch.original_abstracts[i]\n","                article = batch.original_articles[i]\n","                ref_sents.append(abstract)\n","                article_sents.append(article)\n","\n","            batch = self.batcher.next_batch()\n","\n","        load_file = self.opt.load_model\n","\n","        if print_sents:\n","            self.print_original_predicted(decoded_sents, ref_sents, article_sents, load_file)\n","\n","        scores = rouge.get_scores(decoded_sents, ref_sents, avg = True)\n","        if self.opt.task == \"test\":\n","            print(load_file, \"scores:\", scores)\n","        else:\n","            rouge_l = scores[\"rouge-l\"][\"f\"]\n","            print(load_file, \"rouge_l:\", \"%.4f\" % rouge_l)\n","            print('Scores:', scores)\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ff2wdwSxZFoD","colab_type":"text"},"source":["#12. Evaluation and testing using BERTScore"]},{"cell_type":"code","metadata":{"id":"uXvbWRgnZK_O","colab_type":"code","colab":{}},"source":["import os\n","\n","import time\n","\n","import torch as T\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import gc\n","import bert_score\n","import argparse\n","\n","def get_cuda(tensor):\n","    if T.cuda.is_available():\n","        tensor = tensor.cuda()\n","    return tensor\n","\n","class Evaluate(object):\n","    def __init__(self, data_path, opt, batch_size = batch_size):\n","        self.vocab = Vocab(vocab_path, vocab_size)\n","        self.batcher = Batcher(data_path, self.vocab, mode='eval',\n","                               batch_size=batch_size, single_pass=True)\n","        self.opt = opt\n","\n","        time.sleep(5)\n","\n","    def setup_valid(self):\n","        self.model = Model()\n","        self.model = get_cuda(self.model)\n","        checkpoint = T.load(os.path.join(save_model_path, self.opt.load_model))\n","        self.model.load_state_dict(checkpoint[\"model_dict\"])\n","\n","\n","    def print_original_predicted(self, decoded_sents, ref_sents, article_sents, loadfile):\n","        filename = \"test_\"+loadfile.split(\".\")[0]+\".txt\"\n","    \n","        with open(os.path.join(save_example_path,filename), \"w\") as f:\n","            for i in range(len(decoded_sents)):\n","                f.write(\"article: \"+article_sents[i] + \"\\n\")\n","                f.write(\"ref: \" + ref_sents[i] + \"\\n\")\n","                f.write(\"dec: \" + decoded_sents[i] + \"\\n\\n\")\n","\n","    def evaluate_batch(self, print_sents = False):\n","\n","        self.setup_valid()\n","        batch = self.batcher.next_batch()\n","        start_id = self.vocab.word2id(START_DECODING)\n","        end_id = self.vocab.word2id(STOP_DECODING)\n","        unk_id = self.vocab.word2id(UNKNOWN_TOKEN)\n","        decoded_sents = []\n","        ref_sents = []\n","        article_sents = []\n","        #rouge = Rouge()\n","        while batch is not None:\n","            enc_batch, enc_lens, enc_padding_mask, enc_batch_extend_vocab, extra_zeros, ct_e = get_enc_data(batch)\n","\n","            with T.autograd.no_grad():\n","                enc_batch = self.model.embeds(enc_batch)\n","                enc_out, enc_hidden = self.model.encoder(enc_batch, enc_lens)\n","\n","            #-----------------------Summarization----------------------------------------------------\n","            with T.autograd.no_grad():\n","                pred_ids = beam_search(enc_hidden, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, self.model, start_id, end_id, unk_id)\n","\n","            for i in range(len(pred_ids)):\n","                decoded_words = outputids2words(pred_ids[i], self.vocab, batch.art_oovs[i])\n","                if len(decoded_words) < 2:\n","                    decoded_words = \"xxx\"\n","                else:\n","                    decoded_words = \" \".join(decoded_words)\n","                decoded_sents.append(decoded_words)\n","                abstract = batch.original_abstracts[i]\n","                article = batch.original_articles[i]\n","                ref_sents.append(abstract)\n","                article_sents.append(article)\n","\n","            batch = self.batcher.next_batch()\n","\n","        load_file = self.opt.load_model\n","\n","        _,_,f = bert_score.score(decoded_sents, ref_sents, lang='en', verbose = False)\n","\n","        print('{}  score:{}'.format(load_file, f.mean()))\n","        gc.collect()\n","        \n","        if print_sents:\n","            self.print_original_predicted(decoded_sents, ref_sents, article_sents, load_file)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cW5LpXrLacJn","colab_type":"text"},"source":["#13. Model with local attention"]},{"cell_type":"code","metadata":{"id":"OtDOlA52agcK","colab_type":"code","colab":{}},"source":["import torch as T\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","import torch.nn.functional as F\n","\n","\n","def init_lstm_wt(lstm):\n","    for name, _ in lstm.named_parameters():\n","        if 'weight' in name:\n","            wt = getattr(lstm, name)\n","            #print(wt)\n","            wt.data = wt.data.uniform_(-rand_unif_init_mag, rand_unif_init_mag)\n","            #wt.uniform_(-rand_unif_init_mag, rand_unif_init_mag)     #commit\n","        elif 'bias' in name:\n","            # set forget bias to 1\n","            bias = getattr(lstm, name)\n","            n = bias.size(0)\n","            start, end = n // 4, n // 2\n","\n","            bias.data = bias.data.fill_(0.)\n","            #bias.fill_(0.)\n","            bias.data[start:end].fill_(1.)\n","\n","def init_linear_wt(linear):\n","\n","    linear.weight.data = linear.weight.data.normal_(std=trunc_norm_init_std)\n","    #linear.weight.normal_(std=trunc_norm_init_std)\n","    if linear.bias is not None:\n","        linear.bias.data = linear.bias.data.normal_(std=trunc_norm_init_std)\n","        #linear.bias.normal_(std=trunc_norm_init_std)\n","\n","def init_wt_normal(wt):\n","    wt.data = wt.data.normal_(std=trunc_norm_init_std)\n","    #wt.normal_(std=trunc_norm_init_std)\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","\n","        self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)    #batch_true: If True, then the input and output tensors are provided as (batch, seq, feature)\n","        init_lstm_wt(self.lstm)\n","\n","        self.reduce_h = nn.Linear(hidden_dim * 2, hidden_dim)        #hidden state \n","        init_linear_wt(self.reduce_h)\n","        self.reduce_c = nn.Linear(hidden_dim * 2, hidden_dim)\n","        init_linear_wt(self.reduce_c)\n","\n","    def forward(self, x, seq_lens):\n","        packed = pack_padded_sequence(x, seq_lens, batch_first=True)    #accepts any input that has at least two dimensions. You can apply it to pack the labels, and use the output of the RNN with them to compute the loss directly\n","        enc_out, enc_hid = self.lstm(packed)                            # tensor containing the hidden state for t = seq_len. and tensor containing the cell state for t = seq_len.\n","        enc_out,_ = pad_packed_sequence(enc_out, batch_first=True)      \n","        enc_out = enc_out.contiguous()                              #bs, n_seq, 2*n_hid\n","        h, c = enc_hid                                              #shape of h: 2, bs, n_hid\n","        h = T.cat(list(h), dim=1)                                   #bs, 2*n_hid\n","        c = T.cat(list(c), dim=1)\n","        h_reduced = F.relu(self.reduce_h(h))                        #bs,n_hid\n","        c_reduced = F.relu(self.reduce_c(c))\n","        return enc_out, (h_reduced, c_reduced)\n","\n","'''\n","class encoder_attention(nn.Module):\n","\n","    def __init__(self):\n","        super(encoder_attention, self).__init__()\n","        self.W_h = nn.Linear(hidden_dim * 2, hidden_dim * 2, bias=False)    #no bias just the weight matrix\n","        self.W_s = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n","        self.v = nn.Linear(hidden_dim * 2, 1, bias=False)\n","\n","        self.W_p = nn.Linear(hidden_dim * 2, hidden_dim * 2, bias = False)\n","        self.v_p = nn.Linear(hidden_dim * 2, 1, bias = False)\n","\n","    def forward(self, st_hat, h, enc_padding_mask, sum_temporal_srcs, local_attention_d=None):              #INTRA-TEMPORAL ATTENTION ON INPUT SEQUENCE in paper?\n","\n","        Perform attention over encoder hidden states\n","        :param st_hat: decoder hidden state at current time step        (batch_size, 2*hidden_size)\n","        :param h: encoder hidden states     (batch_size, length_input_sequence, 2*hidden_size), length_input is fixed = max_enc_length\n","        :param enc_padding_mask:\n","        :param sum_temporal_srcs: if using intra-temporal attention, contains summation of attention weights from previous decoder time steps\n","        :param local_attention_d: if not None, implement local attention with d instead (eq 9&10 in https://arxiv.org/pdf/1508.04025.pdf)\n","\n","\n","        if local_attention_d is not None:       #perform local  attention\n","            d = local_attention_d\n","            temp_1 = self.W_p(st_hat)           #bs, 2*hid\n","            temp_2 = T.tanh(temp_1)\n","            temp_3 = self.v_p(temp_2)           #bs,1\n","            temp_4 = T.sigmoid(temp_3).squeeze(1)\n","\n","            with T.no_grad():\n","                S = get_cuda(T.zeros(st_hat.shape[0]))        #bs\n","                for i in range(enc_padding_mask.shape[0]):\n","                    temp_len = len(enc_padding_mask[i].nonzero())\n","                    S[i] = temp_len\n","\n","            pt = S * temp_4     #bs\n","            #print('pt before:', pt)\n","            #print('pt',pt)\n","            #construct padding matrix\n","            with T.no_grad():\n","                pt_padding = get_cuda(T.zeros(h.shape[0], h.shape[1]))\n","                for j in range(pt.shape[0]):\n","                    if int(pt[j])-d < 0:\n","                        pt_padding[j, : int(pt[j])+d].fill_(1.)\n","                    elif int(pt[j])+d >= h.shape[1]:\n","                        pt_padding[j, int(pt[j])-d:].fill_(1.)\n","                    else:\n","                        pt_padding[j, int(pt[j])-d: int(pt[j])+d].fill_(1.)\n","            \n","            #print('pt after:', pt_padding)\n","        #print('size of decoder hiddent state:', st_hat.size())\n","        # Standard global attention technique (eq 1 in https://arxiv.org/pdf/1704.04368.pdf)\n","        et = self.W_h(h)                        # bs,n_seq,2*n_hid\n","        dec_fea = self.W_s(st_hat).unsqueeze(1) # bs,1,2*n_hid\n","        et = et + dec_fea\n","        et = T.tanh(et)                         # bs,n_seq,2*n_hid\n","        et = self.v(et).squeeze(2)              # bs,n_seq\n","\n","\n","        # intra-temporal attention     (eq 3 in https://arxiv.org/pdf/1705.04304.pdf)\n","        if intra_encoder:\n","            exp_et = T.exp(et)\n","            if local_attention_d is not None:\n","                exp_et = exp_et * pt_padding        #zero-out the entry outside the window\n","                exp_et = exp_et/ T.sum(exp_et, axis = 1).unsqueeze(1)   #normalised within the window\n","\n","            if sum_temporal_srcs is None:\n","                et1 = exp_et\n","                sum_temporal_srcs  = get_cuda(T.FloatTensor(et.size()).fill_(1e-10)) + exp_et           #defined temporal score\n","            else:\n","                et1 = exp_et/sum_temporal_srcs  #bs, n_seq\n","                sum_temporal_srcs = sum_temporal_srcs + exp_et          #the sum_temporal_src is also returned so that it can be reuse for following encoder attention\n","        else:\n","            et1 = F.softmax(et, dim=1)\n","            if local_attention_d is not None:\n","                et1 = et1 * pt_padding\n","                et1 = et1/T.sum(et1, axis = 1).unsqueeze(1)\n","\n","\n","        # assign 0 probability for padded elements\n","        at = et1 * enc_padding_mask\n","        normalization_factor = at.sum(1, keepdim=True)\n","        at = at / normalization_factor\n","\n","        #gaussian normalisation\n","\n","\n","\n","\n","        at = at.unsqueeze(1)                    #bs,1,n_seq\n","        # Compute encoder context vector\n","        ct_e = T.bmm(at, h)                     #bs, 1, 2*n_hid, batch matrix-matrix product of matrices (temporal score and encoder hidden state)\n","        ct_e = ct_e.squeeze(1)\n","        at = at.squeeze(1)\n","        #print('at',at)\n","        return ct_e, at, sum_temporal_srcs\n","'''\n","\n","class encoder_attention(nn.Module):\n","\n","    def __init__(self):\n","        super(encoder_attention, self).__init__()\n","        self.W_h = nn.Linear(hidden_dim * 2, hidden_dim * 2, bias=False)    #no bias just the weight matrix\n","        self.W_s = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n","        self.v = nn.Linear(hidden_dim * 2, 1, bias=False)\n","\n","        self.W_p = nn.Linear(hidden_dim * 2, hidden_dim * 2, bias = False)\n","        self.v_p = nn.Linear(hidden_dim * 2, 1, bias = False)\n","\n","    def forward(self, st_hat, h, enc_padding_mask, sum_temporal_srcs, local_attention_d=None):              #INTRA-TEMPORAL ATTENTION ON INPUT SEQUENCE in paper?\n","        '''\n","        Perform attention over encoder hidden states\n","        :param st_hat: decoder hidden state at current time step        (batch_size, 2*hidden_size)\n","        :param h: encoder hidden states     (batch_size, length_input_sequence, 2*hidden_size), length_input is fixed = max_enc_length\n","        :param enc_padding_mask:\n","        :param sum_temporal_srcs: if using intra-temporal attention, contains summation of attention weights from previous decoder time steps\n","        :param local_attention_d: if not None, implement local attention with d instead (eq 9&10 in https://arxiv.org/pdf/1508.04025.pdf)\n","        '''\n","        bs = st_hat.shape[0]\n","\n","        if local_attention_d is not None:       #perform local  attention\n","            d = local_attention_d               #window size\n","            std_squared = (d/2)**2              # sigma^2\n","            window_length = 2 * d + 1           #window length\n","            temp_1 = self.W_p(st_hat)           #bs, 2*hid\n","            temp_2 = T.tanh(temp_1)\n","            temp_3 = self.v_p(temp_2)           #bs,1\n","            temp_4 = T.sigmoid(temp_3).squeeze(1)  #probability of position\n","\n","            #retrieve length vector from enc_padding_mask\n","            S = get_cuda(T.zeros(bs))        #bs\n","            for i in range(bs):\n","                temp_len = len(enc_padding_mask[i].nonzero())\n","                S[i] = temp_len\n","            #print('size of S', S.shape)\n","            #print('size of temp_4', temp_4.shape)\n","            pt = S * temp_4     #vector with size [bs], representing the center of window for each batch\n","            #print('pt before:', pt)\n","            #print('pt',pt)\n","\n","            \n","            #construct padding matrix and gaussian matrix\n","            pt_padding = get_cuda(T.zeros(h.shape[0], h.shape[1]))    #[batch_size, max_enc_length], use T.empty cause cuda\n","            position = get_cuda(T.zeros(pt_padding.shape))\n","            window_start = T.round(pt - d).int()\n","            window_end = window_start + window_length\n","            \n","            for i in range(bs):\n","                start = window_start[i].item()\n","                end = window_end[i].item()\n","                if start < 0:\n","                    pt_padding[i, : end].fill_(1.)\n","                    position[i, : end] = get_cuda(T.arange(end, dtype = T.float))    #matrix of index\n","                elif end >= h.shape[1]:     #need to check the index\n","                    pt_padding[i, start:].fill_(1.)\n","                    position[i, start:] = get_cuda(T.arange(start, h.shape[1], dtype = T.float))\n","                else:\n","                    pt_padding[i, start: end].fill_(1.)\n","                    position[i, start:end] = get_cuda(T.arange(start, end, dtype = T.float))\n","            \n","            gaussian = T.exp(-(position - pt.unsqueeze(1))**2 / (2*std_squared))\n","            gaussian = gaussian * pt_padding            #zero-out the entry outside the window\n","            #gaussian = gaussian * enc_padding_mask      #zero-out the padding entry\n","            \n","\n","\n","            \n","            #print('pt after:', pt_padding)\n","        #print('size of decoder hiddent state:', st_hat.size())\n","        # Standard global attention technique (eq 1 in https://arxiv.org/pdf/1704.04368.pdf)\n","        et = self.W_h(h)                        # bs,n_seq,2*n_hid\n","        dec_fea = self.W_s(st_hat).unsqueeze(1) # bs,1,2*n_hid\n","        et = et + dec_fea\n","        et = T.tanh(et)                         # bs,n_seq,2*n_hid\n","        et = self.v(et).squeeze(2)              # bs,n_seq\n","\n","\n","        # intra-temporal attention     (eq 3 in https://arxiv.org/pdf/1705.04304.pdf)\n","        if intra_encoder:\n","            exp_et = T.exp(et)\n","            if local_attention_d is not None:\n","                #print('dimension of exp_et', exp_et.shape)\n","                #print('pt_padding dimension:', pt_padding.shape)\n","                exp_et = exp_et * pt_padding        #zero-out the entry outside the window\n","                #print('pass this')\n","            if sum_temporal_srcs is None:\n","                et1 = exp_et\n","                sum_temporal_srcs  = get_cuda(T.FloatTensor(et.size()).fill_(1e-10)) + exp_et           #defined temporal score\n","            else:\n","                et1 = exp_et/sum_temporal_srcs  #bs, n_seq\n","                sum_temporal_srcs = sum_temporal_srcs + exp_et          #the sum_temporal_src is also returned so that it can be reuse for following encoder attention\n","        else:\n","            et1 = F.softmax(et, dim=1)\n","            if local_attention_d is not None:\n","                et1 = et1 * pt_padding\n","        #print('et1 type', type(et1))\n","        #print('padding type', type(pt_padding))\n","        #print('pd-padding dimenson', pt_padding.shape)\n","        #print('enc_padding_mask dim', enc_padding_mask.shape)\n","        #et1 = et1 * pt_padding\n","        # assign 0 probability for padded elements\n","        #print('et1',et1)\n","        #print('padding', pt_padding)\n","        at = et1 * enc_padding_mask\n","        normalization_factor = at.sum(1, keepdim=True)\n","        at = at / normalization_factor\n","        at = at * gaussian\n","\n","        at = at.unsqueeze(1)                    #bs,1,n_seq\n","        # Compute encoder context vector\n","        ct_e = T.bmm(at, h)                     #bs, 1, 2*n_hid, batch matrix-matrix product of matrices (temporal score and encoder hidden state)\n","        ct_e = ct_e.squeeze(1)\n","        at = at.squeeze(1)\n","        #print('at',at)\n","        return ct_e, at, sum_temporal_srcs\n","\n","\n","\n","\n","\n","\n","class decoder_attention(nn.Module):\n","    def __init__(self):\n","        super(decoder_attention, self).__init__()\n","        if intra_decoder:\n","            self.W_prev = nn.Linear(hidden_dim, hidden_dim, bias=False)        #weight\n","            self.W_s = nn.Linear(hidden_dim, hidden_dim)\n","            self.v = nn.Linear(hidden_dim, 1, bias=False)\n","\n","    def forward(self, s_t, prev_s):\n","        '''Perform intra_decoder attention\n","        Args\n","        :param s_t: hidden state of decoder at current time step\n","        :param prev_s: If intra_decoder attention, contains list of previous decoder hidden states\n","        '''\n","        if intra_decoder is False:\n","            ct_d = get_cuda(T.zeros(s_t.size()))\n","        elif prev_s is None:\n","            ct_d = get_cuda(T.zeros(s_t.size()))\n","            prev_s = s_t.unsqueeze(1)               #bs, 1, n_hid\n","        else:\n","            # Standard attention technique (eq 1 in https://arxiv.org/pdf/1704.04368.pdf)      e = v tanh(Wh + Ws + b)\n","            et = self.W_prev(prev_s)                # bs,t-1,n_hid\n","            dec_fea = self.W_s(s_t).unsqueeze(1)    # bs,1,n_hid\n","            et = et + dec_fea\n","            et = T.tanh(et)                         # bs,t-1,n_hid\n","            et = self.v(et).squeeze(2)              # bs,t-1\n","            # intra-decoder attention     (eq 7 & 8 in https://arxiv.org/pdf/1705.04304.pdf)\n","            at = F.softmax(et, dim=1).unsqueeze(1)  #bs, 1, t-1,  alpha\n","            ct_d = T.bmm(at, prev_s).squeeze(1)     #bs, n_hid\n","            prev_s = T.cat([prev_s, s_t.unsqueeze(1)], dim=1)    #bs, t, n_hid, keep adding previous hidden state \n","\n","        return ct_d, prev_s                 #decoder context vector, previous decoder hidden states\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","        self.enc_attention = encoder_attention()\n","        self.dec_attention = decoder_attention()\n","        self.x_context = nn.Linear(hidden_dim*2 + emb_dim, emb_dim)\n","\n","        self.lstm = nn.LSTMCell(emb_dim, hidden_dim)\n","        init_lstm_wt(self.lstm)\n","\n","        self.p_gen_linear = nn.Linear(hidden_dim * 5 + emb_dim, 1)\n","\n","        #p_vocab\n","        self.V = nn.Linear(hidden_dim*4, hidden_dim)\n","        self.V1 = nn.Linear(hidden_dim, vocab_size)\n","        init_linear_wt(self.V1)\n","\n","    def forward(self, x_t, s_t, enc_out, enc_padding_mask, ct_e, extra_zeros, enc_batch_extend_vocab, sum_temporal_srcs, prev_s):\n","        x = self.x_context(T.cat([x_t, ct_e], dim=1))\n","        s_t = self.lstm(x, s_t)\n","\n","        dec_h, dec_c = s_t\n","        st_hat = T.cat([dec_h, dec_c], dim=1)\n","        ct_e, attn_dist, sum_temporal_srcs = self.enc_attention(st_hat, enc_out, enc_padding_mask, sum_temporal_srcs, local_attention_d)\n","\n","        ct_d, prev_s = self.dec_attention(dec_h, prev_s)        #intra-decoder attention\n","\n","        p_gen = T.cat([ct_e, ct_d, st_hat, x], 1)\n","        p_gen = self.p_gen_linear(p_gen)            # bs,1\n","        p_gen = T.sigmoid(p_gen)                    # bs,1\n","\n","        out = T.cat([dec_h, ct_e, ct_d], dim=1)     # bs, 4*n_hid\n","        out = self.V(out)                           # bs,n_hid\n","        out = self.V1(out)                          # bs, n_vocab\n","        vocab_dist = F.softmax(out, dim=1)\n","        vocab_dist = p_gen * vocab_dist\n","        attn_dist_ = (1 - p_gen) * attn_dist\n","\n","        # pointer mechanism (as suggested in eq 9 https://arxiv.org/pdf/1704.04368.pdf)\n","        if extra_zeros is not None:\n","            vocab_dist = T.cat([vocab_dist, extra_zeros], dim=1)\n","        final_dist = vocab_dist.scatter_add(1, enc_batch_extend_vocab, attn_dist_)\n","\n","        return final_dist, s_t, ct_e, sum_temporal_srcs, prev_s\n","\n","\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder()\n","        self.embeds = nn.Embedding(vocab_size, emb_dim)\n","        init_wt_normal(self.embeds.weight)\n","\n","        self.encoder = get_cuda(self.encoder)\n","        self.decoder = get_cuda(self.decoder)\n","        self.embeds = get_cuda(self.embeds)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bsx7Gdntb4ny","colab_type":"text"},"source":["#14. Experiment"]},{"cell_type":"markdown","metadata":{"id":"D2HH6H5Ii750","colab_type":"text"},"source":["Procedure for each dataset:\n","\n","\n","1.   ML pre-training\n","2.   validating the pre-trained models and select the one with best score\n","3.   Using the same pre-trained model and train ML, ML+RL, RL(r), RL(b)\n","4.   Validating the models\n","5.   Model testing\n"]},{"cell_type":"markdown","metadata":{"id":"BNDterVPezP2","colab_type":"text"},"source":["## Gigaword"]},{"cell_type":"markdown","metadata":{"id":"5BGZ2YlxhORj","colab_type":"text"},"source":["###Hyperparameter"]},{"cell_type":"code","metadata":{"id":"fffuPnIJZLCS","colab_type":"code","colab":{}},"source":["train_data_path = \t\"giga/chunked/train/train_*\"            #training data file\n","valid_data_path = \t\"giga/chunked/valid/valid_00.bin\"       #valdiation data file\n","test_data_path = \t\"giga/chunked/test/test_00.bin\"         #testing data file\n","vocab_path = \t\t\"giga/vocab\"                            #vocab data file\n","\n","\n","# Hyperparameters\n","hidden_dim = 512\n","emb_dim = 256\n","batch_size = 200\n","max_enc_steps = 55\n","max_dec_steps = 15\n","beam_size = 4\n","min_dec_steps= 3\n","vocab_size = 50000\n","\n","lr = 0.001\n","rand_unif_init_mag = 0.02\n","trunc_norm_init_std = 1e-4\n","\n","eps = 1e-12\n","max_iterations = 16000\n","max_batch_queue = 1000          #1000\n","\n","\n","save_model_path = 'RL_BERT'#'giga_pre_model'#'giga_pre_model'  #\"giga_pre_model\"      #!!\n","new_save_model_path = \"RL_BERT\"#'giga_ML'\n","save_example_path = 'example'\n","\n","#new_save_model_path = 'new_models'\n","\n","intra_encoder = True\n","intra_decoder = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2bZQkeFOhUIp","colab_type":"text"},"source":["###Pre-training"]},{"cell_type":"code","metadata":{"id":"7cPCh2BTJvdi","colab_type":"code","outputId":"cb279c4b-a9ac-4252-cf42-1dd1f90a1c19","executionInfo":{"status":"ok","timestamp":1585333356739,"user_tz":0,"elapsed":507,"user":{"displayName":"Yan Song","photoUrl":"","userId":"06548571015088915642"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--train_mle', type=str, default=\"yes\")\n","    parser.add_argument('--train_rl', type=str, default=\"no\")\n","    parser.add_argument('--mle_weight', type=float, default=1.0)\n","    parser.add_argument('--load_model', type=str, default=None)\n","    parser.add_argument('--new_lr', type=float, default=None)\n","\n","    opt, unknown = parser.parse_known_args()\n","    #opt = parser.parse_args()\n","    opt.rl_weight = 1 - opt.mle_weight\n","    print(\"Training mle: %s, Training rl: %s, mle weight: %.2f, rl weight: %.2f\"%(opt.train_mle, opt.train_rl, opt.mle_weight, opt.rl_weight))\n","    print(\"intra_encoder:\", intra_encoder, \"intra_decoder:\",intra_decoder)          #config\n","\n","    train_processor = Train(opt)\n","    train_processor.trainIters()\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"markdown","metadata":{"id":"wJ5Zx3P8hVl2","colab_type":"text"},"source":["###Validation of pre-trained model"]},{"cell_type":"code","metadata":{"id":"4tTL-PPphbJ-","colab_type":"code","colab":{}},"source":["if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--task\", type=str, default=\"validate\", choices=[\"validate\",\"test\"])\n","    parser.add_argument(\"--start_from\", type=str, default=\"0001000.tar\")\n","    parser.add_argument(\"--load_model\", type=str, default=None)\n","    #opt = parser.parse_args()\n","    opt, unknown = parser.parse_known_args()\n","\n","    if opt.task == \"validate\":\n","        saved_models = os.listdir(save_model_path)\n","        saved_models.sort()\n","        file_idx = saved_models.index(opt.start_from)\n","        saved_models = saved_models[file_idx:]\n","        for f in saved_models:\n","            opt.load_model = f\n","            eval_processor = Evaluate(valid_data_path, opt)\n","            eval_processor.evaluate_batch()\n","    else:   #test\n","        eval_processor = Evaluate(test_data_path, opt)\n","        eval_processor.evaluate_batch()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mpAUc_gIhKjr","colab_type":"text"},"source":["###Keep on ML training"]},{"cell_type":"code","metadata":{"id":"dLR6-FX6ht2A","colab_type":"code","colab":{}},"source":["if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--train_mle', type=str, default=\"yes\")\n","    parser.add_argument('--train_rl', type=str, default=\"no\")\n","    parser.add_argument('--mle_weight', type=float, default=1.)\n","    parser.add_argument('--load_model', type=str, default='#######.tar')\n","    parser.add_argument('--new_lr', type=float, default=None)\n","\n","    opt, unknown = parser.parse_known_args()\n","    #opt = parser.parse_args()\n","    opt.rl_weight = 1 - opt.mle_weight\n","    print(\"Training mle: %s, Training rl: %s, mle weight: %.2f, rl weight: %.2f\"%(opt.train_mle, opt.train_rl, opt.mle_weight, opt.rl_weight))\n","    print(\"intra_encoder:\", intra_encoder, \"intra_decoder:\",intra_decoder)          #config\n","\n","    train_processor = Train(opt)\n","    train_processor.trainIters()\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Og3yGDfh4d4","colab_type":"text"},"source":["###KEEP on ML+RL training"]},{"cell_type":"code","metadata":{"id":"-JHfWAKOh8XG","colab_type":"code","colab":{}},"source":["if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--train_mle', type=str, default=\"yes\")\n","    parser.add_argument('--train_rl', type=str, default=\"yes\")\n","    parser.add_argument('--mle_weight', type=float, default=0.5)\n","    parser.add_argument('--load_model', type=str, default='#####.tar')\n","    parser.add_argument('--new_lr', type=float, default=0.0001)\n","\n","    opt, unknown = parser.parse_known_args()\n","    #opt = parser.parse_args()\n","    opt.rl_weight = 1 - opt.mle_weight\n","    print(\"Training mle: %s, Training rl: %s, mle weight: %.2f, rl weight: %.2f\"%(opt.train_mle, opt.train_rl, opt.mle_weight, opt.rl_weight))\n","    print(\"intra_encoder:\", intra_encoder, \"intra_decoder:\",intra_decoder)          #config\n","\n","    train_processor = Train(opt)\n","    train_processor.trainIters()\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X20pf5AKiUnt","colab_type":"text"},"source":["###Keep on RL(r/b) training"]},{"cell_type":"code","metadata":{"id":"5l5a6vjbiZ1F","colab_type":"code","colab":{}},"source":["if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--train_mle', type=str, default=\"no\")\n","    parser.add_argument('--train_rl', type=str, default=\"yes\")\n","    parser.add_argument('--mle_weight', type=float, default=0.)\n","    parser.add_argument('--load_model', type=str, default='#####.tar')\n","    parser.add_argument('--new_lr', type=float, default=0.0001)\n","\n","    opt, unknown = parser.parse_known_args()\n","    #opt = parser.parse_args()\n","    opt.rl_weight = 1 - opt.mle_weight\n","    print(\"Training mle: %s, Training rl: %s, mle weight: %.2f, rl weight: %.2f\"%(opt.train_mle, opt.train_rl, opt.mle_weight, opt.rl_weight))\n","    print(\"intra_encoder:\", intra_encoder, \"intra_decoder:\",intra_decoder)          #config\n","\n","    train_processor = Train(opt)\n","    train_processor.trainIters()\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yRGdIvD9iY4o","colab_type":"text"},"source":["###Validation"]},{"cell_type":"code","metadata":{"id":"oOoZi_rJhuqV","colab_type":"code","colab":{}},"source":["if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--task\", type=str, default=\"validate\", choices=[\"validate\",\"test\"])\n","    parser.add_argument(\"--start_from\", type=str, default=\"######.tar\")\n","    parser.add_argument(\"--load_model\", type=str, default=None)\n","    #opt = parser.parse_args()\n","    opt, unknown = parser.parse_known_args()\n","\n","    if opt.task == \"validate\":\n","        saved_models = os.listdir(save_model_path)\n","        saved_models.sort()\n","        file_idx = saved_models.index(opt.start_from)\n","        saved_models = saved_models[file_idx:]\n","        for f in saved_models:\n","            opt.load_model = f\n","            eval_processor = Evaluate(valid_data_path, opt)\n","            eval_processor.evaluate_batch()\n","    else:   #test\n","        eval_processor = Evaluate(test_data_path, opt)\n","        eval_processor.evaluate_batch()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9p3RurXiioAC","colab_type":"text"},"source":["###Testing and print out examples"]},{"cell_type":"code","metadata":{"id":"_wwH0ESZhus7","colab_type":"code","colab":{}},"source":["if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--task\", type=str, default=\"test\", choices=[\"validate\",\"test\"])\n","    parser.add_argument(\"--start_from\", type=str, default=\"######.tar\")\n","    parser.add_argument(\"--load_model\", type=str, default=None)\n","    #opt = parser.parse_args()\n","    opt, unknown = parser.parse_known_args()\n","\n","    if opt.task == \"validate\":\n","        saved_models = os.listdir(save_model_path)\n","        saved_models.sort()\n","        file_idx = saved_models.index(opt.start_from)\n","        saved_models = saved_models[file_idx:]\n","        for f in saved_models:\n","            opt.load_model = f\n","            eval_processor = Evaluate(valid_data_path, opt)\n","            eval_processor.evaluate_batch()\n","    else:   #test\n","        eval_processor = Evaluate(test_data_path, opt)\n","        eval_processor.evaluate_batch(print=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b1tgtFowj1HD","colab_type":"text"},"source":["##CNN/DM datasets"]},{"cell_type":"markdown","metadata":{"id":"JplmCmEMj44A","colab_type":"text"},"source":["###Hyperparameter"]},{"cell_type":"code","metadata":{"id":"iYZvu9UVhuvc","colab_type":"code","colab":{}},"source":["train_data_path = \t\"/content/drive/My Drive/NLPproject/CNNDM/finished_files/finished_files/chunked/train_*\"               #this is where you save the training data\n","valid_data_path = \t\"drive/My Drive/NLPProject/valid.bin\"                           #this is where you save the validation data\n","test_data_path = \t\"drive/My Drive/NLPProject/chunked/main_test/test_*\"            #this is where you save the testing data\n","vocab_path = \t\t\"drive/My Drive/NLPProject/vocab\"                               #this is where you save the vocab file\n","\n","\n","# Hyperparameters\n","hidden_dim = 400\n","emb_dim = 200\n","batch_size = 50\n","max_enc_steps = 400\t\t\n","max_dec_steps = 100\t\t\n","beam_size = 5\n","min_dec_steps= 3\n","vocab_size = 30000 \n","\n","lr = 0.001\n","rand_unif_init_mag = 0.02\n","trunc_norm_init_std = 1e-4\n","\n","eps = 1e-12\n","max_iterations = 10000\n","max_batch_queue = 100\n","\n","\n","save_model_path = \"drive/My Drive/NLPProject/CNNDM\"                                 #this is where you save your pre-trained model\n","new_save_mode_path = '....'                                                         #this is where you save your new training model\n","\n","intra_encoder = True\n","intra_decoder = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HfIvD4EhkXJK","colab_type":"text"},"source":["##WikiHow dataset"]},{"cell_type":"markdown","metadata":{"id":"n2AZhONzkY91","colab_type":"text"},"source":["###Hyperpatameter"]},{"cell_type":"code","metadata":{"id":"qyE0MlOwkjIU","colab_type":"code","colab":{}},"source":["train_data_path = '/datasets/wiki_train/train_*'\n","valid_data_path = \t\"wiki_valid/valid_0000.bin\"\n","test_data_path = \t\"wiki_test/test_0000.bin\"   \n","vocab_path = \t\t\"wiki_vocab/vocab_wiki\"\n","\n","\n","# Hyperparameters\n","hidden_dim = 512\n","emb_dim = 256\n","batch_size = 10\n","max_enc_steps = 500\n","max_dec_steps = 100\n","beam_size = 4\n","min_dec_steps= 3\n","vocab_size = 20000\n","\n","lr = 0.001\n","rand_unif_init_mag = 0.02\n","trunc_norm_init_std = 1e-4\n","\n","eps = 1e-12\n","max_iterations = 16000\n","max_batch_queue = 30 \n","\n","\n","save_model_path = 'wiki RL BERT'     #!!\n","save_example_path = 'example'\n","#new_save_model_path = 'wiki RL BERT'\n","\n","intra_encoder = True\n","intra_decoder = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TvvT6m6Rk3h2","colab_type":"text"},"source":["###Local attention model hyperparameter"]},{"cell_type":"code","metadata":{"id":"-1Iqs5Ytk6Ul","colab_type":"code","colab":{}},"source":["train_data_path =   '/datasets/wiki_train/train_*'\n","valid_data_path =  'wiki_valid/valid_0000.bin'\n","test_data_path = 'wiki_test/test_0004.bin'\n","vocab_path = \t\t'wiki_vocab/vocab_wiki'\n","   #this is the location of vocab                                                            #\"drive/My Drive/WikiHow_bin/vocab_wiki\"\n","\n","\n","# Hyperparameters\n","hidden_dim = 512\n","emb_dim = 256\n","batch_size =  10         #10\n","max_enc_steps = 500\n","max_dec_steps = 150\n","beam_size = 4\n","min_dec_steps= 3\n","vocab_size = 20000\n","\n","lr = 0.001\n","rand_unif_init_mag = 0.02\n","trunc_norm_init_std = 1e-4\n","\n","eps = 1e-12\n","max_iterations = 15000\n","\n","\n","save_model_path = 'local pre-train' #'local pre-train'  #this is the location of pre-trained model                                          #'drive/My Drive/RL_wiki_model'             #\"drive/My Drive/wiki_model\"\n","new_save_model_path = 'local RLb'  #this is the location you want your new model to be saved    #'drive/My Drive/RL_wiki_model'\n","save_example_path = 'example'\n","\n","intra_encoder = False\n","intra_decoder = True\n","local_attention_d = 50  #or 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z7U8Pzz7kjLd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLioLWv9huxb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
#-----------------------training--------------------------#
Training mle: yes, Training rl: no, mle weight: 1.00, rl weight: 0.00
intra_encoder: True intra_decoder: True

iter: 200 mle_loss: 5.409 reward: 0.0000

iter: 400 mle_loss: 5.014 reward: 0.0000

iter: 600 mle_loss: 4.889 reward: 0.0000

iter: 800 mle_loss: 4.783 reward: 0.0000
iter: 1000 mle_loss: 4.705 reward: 0.0000
iter: 1200 mle_loss: 4.629 reward: 0.0000
iter: 1400 mle_loss: 4.577 reward: 0.0000
iter: 1600 mle_loss: 4.540 reward: 0.0000
iter: 1800 mle_loss: 4.485 reward: 0.0000
iter: 2000 mle_loss: 4.462 reward: 0.0000
iter: 2200 mle_loss: 4.424 reward: 0.0000
iter: 2400 mle_loss: 4.407 reward: 0.0000
iter: 2600 mle_loss: 4.363 reward: 0.0000
iter: 2800 mle_loss: 4.352 reward: 0.0000
iter: 3000 mle_loss: 4.319 reward: 0.0000
iter: 3200 mle_loss: 4.304 reward: 0.0000
iter: 3400 mle_loss: 4.290 reward: 0.0000
iter: 3600 mle_loss: 4.255 reward: 0.0000
iter: 3800 mle_loss: 4.245 reward: 0.0000
iter: 4000 mle_loss: 4.223 reward: 0.0000
iter: 4200 mle_loss: 4.203 reward: 0.0000

iter: 4400 mle_loss: 4.199 reward: 0.0000

iter: 4600 mle_loss: 4.184 reward: 0.0000

iter: 4800 mle_loss: 4.173 reward: 0.0000

iter: 5000 mle_loss: 4.161 reward: 0.0000

iter: 5200 mle_loss: 4.147 reward: 0.0000

iter: 5400 mle_loss: 4.147 reward: 0.0000

iter: 5600 mle_loss: 4.140 reward: 0.0000

iter: 5800 mle_loss: 4.120 reward: 0.0000

iter: 6000 mle_loss: 4.117 reward: 0.0000

iter: 6200 mle_loss: 4.118 reward: 0.0000

iter: 6400 mle_loss: 4.115 reward: 0.0000

iter: 6600 mle_loss: 4.090 reward: 0.0000

iter: 6800 mle_loss: 4.089 reward: 0.0000

iter: 7000 mle_loss: 4.089 reward: 0.0000

iter: 7200 mle_loss: 4.080 reward: 0.0000

iter: 7400 mle_loss: 4.056 reward: 0.0000

iter: 7600 mle_loss: 4.050 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 199900
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 7800 mle_loss: 4.044 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 8000 mle_loss: 4.046 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 8200 mle_loss: 4.021 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 8400 mle_loss: 4.035 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 199925
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 8600 mle_loss: 4.023 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 8800 mle_loss: 4.016 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 9000 mle_loss: 4.011 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 9200 mle_loss: 4.013 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 9400 mle_loss: 4.012 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 9600 mle_loss: 4.000 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
iter: 9800 mle_loss: 3.999 reward: 0.0000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000
INFO:tensorflow:Bucket queue size: 1000, Input queue size: 200000

iter: 10000 mle_loss: 3.998 reward: 0.0000





#---------------------validating----------------------------–#




0002000.tar rouge_l: 0.3203
Scores: {'rouge-1': {'f': 0.3026268100718435, 'p': 0.378840702947845, 'r': 0.2610528993340573}, 'rouge-2': {'f': 0.09185012347478012, 'p': 0.1134005102040817, 'r': 0.08077239922775649}, 'rouge-l': {'f': 0.32025051439121865, 'p': 0.4944353741496597, 'r': 0.2507213605874089}}



0003000.tar rouge_l: 0.3391
Scores: {'rouge-1': {'f': 0.31947920731857365, 'p': 0.38520029375386367, 'r': 0.2819232841583341}, 'rouge-2': {'f': 0.1047890997719137, 'p': 0.1265371315192743, 'r': 0.09322404567887779}, 'rouge-l': {'f': 0.33912504943815996, 'p': 0.5074991496598635, 'r': 0.2696444996565563}}



0004000.tar rouge_l: 0.3473
Scores: {'rouge-1': {'f': 0.32982416479286986, 'p': 0.3971120645227783, 'r': 0.2917972415398767}, 'rouge-2': {'f': 0.11638810389164614, 'p': 0.13915960626674898, 'r': 0.10435152137778199}, 'rouge-l': {'f': 0.3473034425398077, 'p': 0.5047193877551012, 'r': 0.2794748029367823}}



0005000.tar rouge_l: 0.3507
Scores: {'rouge-1': {'f': 0.3312188931867065, 'p': 0.3994283652855075, 'r': 0.29246200244791987}, 'rouge-2': {'f': 0.11540311814742138, 'p': 0.13805784889713446, 'r': 0.10327202775049425}, 'rouge-l': {'f': 0.3507435449575681, 'p': 0.5166547619047619, 'r': 0.28034532597117023}}



0006000.tar rouge_l: 0.3576
Scores: {'rouge-1': {'f': 0.3383906261797663, 'p': 0.4025645386359666, 'r': 0.3020930539994824}, 'rouge-2': {'f': 0.11793389062800322, 'p': 0.14018424036281163, 'r': 0.10633589613001389}, 'rouge-l': {'f': 0.3575655489024178, 'p': 0.5187247732426313, 'r': 0.2896484874506202}}



0007000.tar rouge_l: 0.3549
Scores: {'rouge-1': {'f': 0.3386748226991907, 'p': 0.411850133992991, 'r': 0.29765904669317306}, 'rouge-2': {'f': 0.11968721401289424, 'p': 0.14474263038548735, 'r': 0.10681171227232156}, 'rouge-l': {'f': 0.35490461291356, 'p': 0.52453231292517, 'r': 0.28372948674503756}}



0008000.tar rouge_l: 0.3575
Scores: {'rouge-1': {'f': 0.34123656302003974, 'p': 0.4122046643832353, 'r': 0.3011001615423764}, 'rouge-2': {'f': 0.12410707361700704, 'p': 0.14980274685631811, 'r': 0.11056009227700403}, 'rouge-l': {'f': 0.3574610544376439, 'p': 0.5225008503401354, 'r': 0.28777095350656723}}



0009000.tar rouge_l: 0.3637
Scores: {'rouge-1': {'f': 0.3420489329925434, 'p': 0.40443233353947605, 'r': 0.3070423982221906}, 'rouge-2': {'f': 0.12111171844438924, 'p': 0.14304032475461032, 'r': 0.10988078634717297}, 'rouge-l': {'f': 0.3636991451487642, 'p': 0.529212018140589, 'r': 0.293342137627829}}



0010000.tar rouge_l: 0.3573
Scores: {'rouge-1': {'f': 0.3394372557594023, 'p': 0.4083361678004538, 'r': 0.30104885071931065}, 'rouge-2': {'f': 0.12501570337493872, 'p': 0.14943878343878322, 'r': 0.11257375549287313}, 'rouge-l': {'f': 0.3573300308504835, 'p': 0.5206031746031751, 'r': 0.28869282796730705}}



#----------------------------------testing------------------------------––#
0009000.tar scores: {'rouge-1': {'f': 0.3402192040424947, 'p': 0.4000086837765413, 'r': 0.30698975474437046}, 'rouge-2': {'f': 0.1278450109972135, 'p': 0.14787868480725605, 'r': 0.11774609715681146}, 'rouge-l': {'f': 0.36425123287853933, 'p': 0.5284957482993199, 'r': 0.2958076597035573}}




